{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":7173,"status":"ok","timestamp":1660831148350,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"cWACPRL869I4"},"outputs":[],"source":["!pip install gym \u003e/dev/null"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5763,"status":"ok","timestamp":1660831154105,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"2Os6feRY6ec_"},"outputs":[],"source":["!pip install JSAnimation \u003e/dev/null"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1660831154106,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"wotUOa_e6edP"},"outputs":[],"source":["%matplotlib inline\n","from JSAnimation.IPython_display import display_animation\n","from matplotlib import animation\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","\n","def display_frames_as_gif(frames):\n","    \"\"\"\n","    Displays a list of frames as a gif, with controls\n","    \"\"\"\n","    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n","    patch = plt.imshow(frames[0])\n","    plt.axis('off')\n","\n","    def animate(i):\n","        patch.set_data(frames[i])\n","\n","    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n","    HTML(anim.to_jshtml())"]},{"cell_type":"markdown","metadata":{"id":"R66_INeZ9nYX"},"source":["## Step 2: Playing Pong"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28759,"status":"ok","timestamp":1660831182854,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"8ngMhg3fB9aA","outputId":"a524e6b6-6d80-4b41-ba9d-3d3b8fa1be23"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n","Requirement already satisfied: importlib-metadata\u003e=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n","Requirement already satisfied: gym-notices\u003e=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n","Requirement already satisfied: cloudpickle\u003e=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n","Requirement already satisfied: numpy\u003e=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n","Collecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Collecting ale-py~=0.7.5\n","  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5-\u003egym[accept-rom-license,atari]) (5.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2-\u003egym[accept-rom-license,atari]) (2.23.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2-\u003egym[accept-rom-license,atari]) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2-\u003egym[accept-rom-license,atari]) (4.64.0)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.8.0-\u003egym[accept-rom-license,atari]) (3.8.1)\n","Requirement already satisfied: typing-extensions\u003e=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.8.0-\u003egym[accept-rom-license,atari]) (4.1.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eautorom[accept-rom-license]~=0.4.2-\u003egym[accept-rom-license,atari]) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eautorom[accept-rom-license]~=0.4.2-\u003egym[accept-rom-license,atari]) (2022.6.15)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eautorom[accept-rom-license]~=0.4.2-\u003egym[accept-rom-license,atari]) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-\u003eautorom[accept-rom-license]~=0.4.2-\u003egym[accept-rom-license,atari]) (3.0.4)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=56d5c72ec4835dd25a8f10b0b9f259ce7f0d5d86de0e2dd15ef6bf61db4f284d\n","  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n","Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"]}],"source":["%pip install -U gym\u003e=0.21.0\n","%pip install -U gym[atari,accept-rom-license]"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1041,"status":"ok","timestamp":1660831183778,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"MtT2GyK_6edc","outputId":"8dcfb5a9-a0eb-46b1-c136-eeed4d11ace7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  f\"The environment {id} is out of date. You should consider \"\n","/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}],"source":["import gym\n","env = gym.make('Pong-v0')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1660831183779,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"oRE6WmXQJ1Z0","outputId":"5fa01ca7-affc-4f40-f194-09b782f35d03"},"outputs":[{"data":{"text/plain":["Discrete(6)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["env.action_space"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1660831183973,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"yl_9d4HFJ31W","outputId":"4ce9c8b0-da52-40c7-eec3-16ae10c3dd7e"},"outputs":[{"data":{"text/plain":["Box(0, 255, (210, 160, 3), uint8)"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["env.observation_space"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":621,"status":"ok","timestamp":1660831184587,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"trwRXI-h6eeI","outputId":"dd7f200d-d026-4786-a52f-65bf89580a6c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n","  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  \"Core environment is written in old step API which returns one bool instead of two. \"\n"]},{"name":"stdout","output_type":"stream","text":["Episode finished without success, accumulated reward = -10.0\n"]}],"source":["# Run a demo of the environment\n","observation = env.reset()\n","cumulated_reward = 0\n","\n","frames = []\n","for t in range(1000):\n","#     print(observation)\n","    frames.append(env.render(mode = 'rgb_array'))\n","    # very stupid agent, just makes a random action within the allowd action space\n","    action = env.action_space.sample()\n","#     print(\"Action: {}\".format(t+1))    \n","    observation, reward, done, info = env.step(action)\n","#     print(reward)\n","    cumulated_reward += reward\n","    if done:\n","        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","        break\n","print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","\n","env.close()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1660831184587,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"3zZTecVWLLes"},"outputs":[],"source":["def sigmoid(x): \n","  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n","\n","def prepro(I):\n","  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n","  I = I[35:195] # crop\n","  I = I[::2,::2,0] # downsample by factor of 2\n","  I[I == 144] = 0 # erase background (background type 1)\n","  I[I == 109] = 0 # erase background (background type 2)\n","  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n","  return I.astype(np.float).ravel()\n","\n","def policy_forward(x):\n","  h = np.dot(model['W1'], x)\n","  h[h\u003c0] = 0 # ReLU nonlinearity\n","  logp = np.dot(model['W2'], h)\n","  p = sigmoid(logp)\n","  return p, h # return probability of taking action 2, and hidden state\n","\n","def model_step(model, observation, prev_x):\n","  # preprocess the observation, set input to network to be difference image\n","  cur_x = prepro(observation)\n","  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","  prev_x = cur_x\n","  \n","  # forward the policy network and sample an action from the returned probability\n","  aprob, _ = policy_forward(x)\n","  action = 2 if aprob \u003e= 0.5 else 3 # roll the dice!\n","  \n","  return action, prev_x\n","\n","def play_game(env, model):\n","  observation = env.reset()\n","\n","  frames = []\n","  cumulated_reward = 0\n","\n","  prev_x = None # used in computing the difference frame\n","\n","  for t in range(1000):\n","      frames.append(env.render(mode = 'rgb_array'))\n","      action, prev_x = model_step(model, observation, prev_x)\n","      observation, reward, done, info = env.step(action)\n","      cumulated_reward += reward\n","      if done:\n","          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","          break\n","  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","  display_frames_as_gif(frames)\n","  env.close()"]},{"cell_type":"markdown","metadata":{"id":"6gWvZQ7AQLQt"},"source":["## Step 3: Policy Gradient from Scratch"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1660831184588,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"eqFm7hqcItWl"},"outputs":[],"source":["import numpy as np\n","\n","# model initialization\n","H = 200 # number of hidden layer neurons\n","D = 80 * 80 # input dimensionality: 80x80 grid\n","model = {}\n","model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n","model['W2'] = np.random.randn(H) / np.sqrt(H)\n","\n","# import pickle\n","# model = pickle.load(open('model.pkl', 'rb'))"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1660831184588,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"TwjiwKisQM19"},"outputs":[],"source":["# hyperparameters\n","batch_size = 10 # every how many episodes to do a param update?\n","# learning_rate = 1e-4\n","learning_rate = 1e-2\n"," \n","gamma = 0.99 # discount factor for reward\n","decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n","  \n","grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n","rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n","\n","def discount_rewards(r):\n","  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n","  discounted_r = np.zeros_like(r, dtype=np.float32)\n","  running_add = 0\n","  for t in reversed(range(0, r.size)):\n","    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n","    running_add = running_add * gamma + r[t]\n","    discounted_r[t] = running_add\n","  return discounted_r\n","\n","def policy_backward(epx, eph, epdlogp):\n","  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n","  dW2 = np.dot(eph.T, epdlogp).ravel()\n","  dh = np.outer(epdlogp, model['W2'])\n","  dh[eph \u003c= 0] = 0 # backpro prelu\n","  dW1 = np.dot(dh.T, epx)\n","  return {'W1':dW1, 'W2':dW2}\n","\n","def train_model(env, model, total_episodes = 100):\n","  hist = []\n","  observation = env.reset()\n","\n","  prev_x = None # used in computing the difference frame\n","  xs,hs,dlogps,drs = [],[],[],[]\n","  running_reward = None\n","  reward_sum = 0\n","  episode_number = 0\n","\n","  while True:\n","    # preprocess the observation, set input to network to be difference image\n","    cur_x = prepro(observation)\n","    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","    prev_x = cur_x\n","\n","    # forward the policy network and sample an action from the returned probability\n","    aprob, h = policy_forward(x)\n","    action = 2 if np.random.uniform() \u003c aprob else 3 # roll the dice!\n","\n","    # record various intermediates (needed later for backprop)\n","    xs.append(x) # observation\n","    hs.append(h) # hidden state\n","    y = 1 if action == 2 else 0 # a \"fake label\"\n","    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n","\n","    # step the environment and get new measurements\n","    observation, reward, done, info = env.step(action)\n","    reward_sum += reward\n","\n","    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n","\n","    if done: # an episode finished\n","      episode_number += 1\n","\n","      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n","      epx = np.vstack(xs)\n","      eph = np.vstack(hs)\n","      epdlogp = np.vstack(dlogps)\n","      epr = np.vstack(drs)\n","      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n","\n","      # compute the discounted reward backwards through time\n","      discounted_epr = discount_rewards(epr)\n","      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n","      discounted_epr -= np.mean(discounted_epr)\n","      discounted_epr /= np.std(discounted_epr)\n","\n","      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n","      grad = policy_backward(epx, eph, epdlogp)\n","      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n","\n","      # perform rmsprop parameter update every batch_size episodes\n","      if episode_number % batch_size == 0:\n","        for k,v in model.items():\n","          g = grad_buffer[k] # gradient\n","          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n","          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n","          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n","\n","      # boring book-keeping\n","      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n","      hist.append((episode_number, reward_sum, running_reward))\n","      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n","      reward_sum = 0\n","      observation = env.reset() # reset env\n","      prev_x = None\n","      if episode_number == total_episodes: return hist\n","\n","      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n","        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":995467,"status":"ok","timestamp":1660832180048,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"G6Ka_5Vl9Orm","outputId":"551b824b-9d0d-464e-a455-3396455c04a7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"name":"stdout","output_type":"stream","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -20.990100\n","resetting env. episode 4.000000, reward total was -20.000000. running mean: -20.980199\n","resetting env. episode 5.000000, reward total was -20.000000. running mean: -20.970397\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.970693\n","resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.970986\n","resetting env. episode 8.000000, reward total was -19.000000. running mean: -20.951276\n","resetting env. episode 9.000000, reward total was -20.000000. running mean: -20.941763\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.942346\n","resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.942922\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.943493\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.944058\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.944618\n","resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.945171\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.945720\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.946263\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.946800\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.947332\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.947859\n","resetting env. episode 21.000000, reward total was -20.000000. running mean: -20.938380\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.938996\n","resetting env. episode 23.000000, reward total was -20.000000. running mean: -20.929606\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.930310\n","resetting env. episode 25.000000, reward total was -19.000000. running mean: -20.911007\n","resetting env. episode 26.000000, reward total was -19.000000. running mean: -20.891897\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.892978\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.894048\n","resetting env. episode 29.000000, reward total was -19.000000. running mean: -20.875108\n","resetting env. episode 30.000000, reward total was -20.000000. running mean: -20.866357\n","resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.867693\n","resetting env. episode 32.000000, reward total was -19.000000. running mean: -20.849016\n","resetting env. episode 33.000000, reward total was -20.000000. running mean: -20.840526\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.842121\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.843700\n","resetting env. episode 36.000000, reward total was -19.000000. running mean: -20.825263\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.827010\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.828740\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.830452\n","resetting env. episode 40.000000, reward total was -19.000000. running mean: -20.812148\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.814026\n","resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.815886\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.817727\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.819550\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.821355\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.823141\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.824910\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.826661\n","resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.828394\n","resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.830110\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.831809\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.833491\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.835156\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.836804\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.838436\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.840052\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.841651\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.843235\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.844803\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.846355\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.847891\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.849412\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.850918\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.852409\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.853885\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.855346\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.856792\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.858224\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.859642\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.861046\n","resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.862435\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.863811\n","resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.865173\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.866521\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.867856\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.869177\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.870486\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.871781\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.873063\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.874332\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.875589\n","resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.876833\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.878065\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.879284\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.880491\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.881686\n","resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.882869\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.884041\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.885200\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.886348\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.887485\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.888610\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.889724\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.890827\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.891918\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.892999\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.894069\n","resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.895129\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.896177\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.897216\n","resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.898243\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.899261\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.900268\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.901266\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.902253\n","resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.893230\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.894298\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.895355\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.896402\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.897438\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.898463\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.899479\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.900484\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.901479\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.902464\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.903440\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.904405\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.905361\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.906307\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.907244\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.908172\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.909090\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.909999\n","resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.910899\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.911790\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.912672\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.913546\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.914410\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.915266\n","resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.916113\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.916952\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.917783\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.918605\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.919419\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.920225\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.921023\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.921812\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.922594\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.923368\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.924135\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.924893\n","resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.925644\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.926388\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.927124\n","resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.927853\n","resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.928574\n","resetting env. episode 147.000000, reward total was -20.000000. running mean: -20.919288\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.920096\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.920895\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.921686\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.922469\n","resetting env. episode 152.000000, reward total was -20.000000. running mean: -20.913244\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.914112\n","resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.914971\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.915821\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.916663\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.917496\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.918321\n","resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.919138\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.919946\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.920747\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.921540\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.922324\n","resetting env. episode 164.000000, reward total was -20.000000. running mean: -20.913101\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.913970\n","resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.914830\n","resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.915682\n","resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.916525\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.917360\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.918186\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.919004\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.919814\n","resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.920616\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.921410\n","resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.922196\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.922974\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.923744\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.924507\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.925262\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.926009\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.926749\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.927481\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.928207\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.928925\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.929635\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.930339\n","resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.931036\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.931725\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.932408\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.933084\n","resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.923753\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.924516\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.925270\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.926018\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.926758\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.927490\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.928215\n","resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.928933\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.929644\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.930347\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.931044\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.931733\n","resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.932416\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.933092\n","resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.933761\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.934423\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.935079\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.935728\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.936371\n","resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.937007\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.937637\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.938261\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.938878\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.939489\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.940094\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.940694\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.941287\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.941874\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.942455\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.943030\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.943600\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.944164\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.944722\n","resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.945275\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.945823\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.946364\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.946901\n","resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.947432\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.947957\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.948478\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.948993\n","resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.949503\n","resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.950008\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.940508\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.941103\n","resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.941692\n","resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.942275\n","resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.942852\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.943424\n","resetting env. episode 240.000000, reward total was -20.000000. running mean: -20.933989\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.934650\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.935303\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.935950\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.936590\n","resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.937225\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.937852\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.938474\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.939089\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.939698\n","resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.940301\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.940898\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.941489\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.942074\n","resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.932654\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.933327\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.933994\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.934654\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.935307\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.935954\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.936595\n","resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.937229\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.937856\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.938478\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.939093\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.939702\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.930305\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.931002\n","resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.931692\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.932375\n","resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.933051\n","resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.933721\n","resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.934384\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.935040\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.935689\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.936333\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.936969\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.937600\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.938224\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.938841\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.939453\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.940058\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.940658\n","resetting env. episode 283.000000, reward total was -20.000000. running mean: -20.931251\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.931939\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.932619\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.933293\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.933960\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.934621\n","resetting env. episode 289.000000, reward total was -20.000000. running mean: -20.925274\n","resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.926022\n","resetting env. episode 291.000000, reward total was -19.000000. running mean: -20.906761\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.897694\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.898717\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.899730\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.900732\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.901725\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.902708\n","resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.893681\n","resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.894744\n","resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.895796\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.896839\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.897870\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.898891\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.899903\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.900903\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.901894\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.902876\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.903847\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.904808\n","resetting env. episode 310.000000, reward total was -20.000000. running mean: -20.895760\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.896803\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.897835\n","resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.898856\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.899868\n","resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.900869\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.901860\n","resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.902842\n","resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.903813\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.904775\n","resetting env. episode 320.000000, reward total was -20.000000. running mean: -20.895727\n","resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.886770\n","resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.887902\n","resetting env. episode 323.000000, reward total was -20.000000. running mean: -20.879023\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.880233\n","resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.881431\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.882617\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.883790\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.884952\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.886103\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.887242\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.888369\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.889486\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.890591\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.891685\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.892768\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.893840\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.894902\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.895953\n","resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.896994\n","resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.898024\n","resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.899043\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.900053\n","resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.901052\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.902042\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.903021\n","resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.903991\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.904951\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.905902\n","resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.896843\n","resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.897874\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.898896\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.899907\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.900908\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.901899\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.902880\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.903851\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.904812\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.905764\n","resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.896706\n","resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.897739\n","resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.898762\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.899774\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.900777\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.901769\n","resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.902751\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.903724\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.904686\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.905640\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.906583\n","resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.907517\n","resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.908442\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.909358\n","resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.910264\n","resetting env. episode 374.000000, reward total was -20.000000. running mean: -20.901162\n","resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.902150\n","resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.903128\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.904097\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.905056\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.906006\n","resetting env. episode 380.000000, reward total was -20.000000. running mean: -20.896946\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.897976\n","resetting env. episode 382.000000, reward total was -20.000000. running mean: -20.888996\n","resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.890106\n","resetting env. episode 384.000000, reward total was -21.000000. running mean: -20.891205\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.892293\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.893370\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.894437\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.895492\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.896537\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.897572\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.898596\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.899610\n","resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.890614\n","resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.881708\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.882891\n","resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.874062\n","resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.865321\n","resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.866668\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.868002\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.869322\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.870628\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.871922\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.873203\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.874471\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.875726\n","resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.866969\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.868299\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.869616\n","resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.860920\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.862311\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.863688\n","resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.865051\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.866400\n","resetting env. episode 414.000000, reward total was -20.000000. running mean: -20.857736\n","resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.849159\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.850667\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.852161\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.853639\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.855103\n","resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.856552\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.857986\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.859406\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.850812\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.852304\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.853781\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.855243\n","resetting env. episode 427.000000, reward total was -20.000000. running mean: -20.846691\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.848224\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.849742\n","resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.851244\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.852732\n","resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.854204\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.855662\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.857106\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.858535\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.859949\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.861350\n","resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.862736\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.864109\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.865468\n","resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.856813\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.858245\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.859663\n","resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.861066\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.862455\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.863831\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.865193\n","resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.866541\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.867875\n","resetting env. episode 450.000000, reward total was -20.000000. running mean: -20.859196\n","resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.860604\n","resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.861998\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.863378\n","resetting env. episode 454.000000, reward total was -20.000000. running mean: -20.854745\n","resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.856197\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.857635\n","resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.859059\n","resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.860468\n","resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.851864\n","resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.843345\n","resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.844912\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.846462\n","resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.847998\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.849518\n","resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.851023\n","resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.852512\n","resetting env. episode 467.000000, reward total was -19.000000. running mean: -20.833987\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.835647\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.837291\n","resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.828918\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.830629\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.832323\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.833999\n","resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.835659\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.837303\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.838930\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.840540\n","resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.842135\n","resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.843714\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.845277\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.846824\n","resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.848356\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.849872\n","resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.851373\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.852860\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.854331\n","resetting env. episode 487.000000, reward total was -20.000000. running mean: -20.845788\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.847330\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.848856\n","resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.840368\n","resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.841964\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.843545\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.845109\n","resetting env. episode 494.000000, reward total was -20.000000. running mean: -20.836658\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.838291\n","resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.839909\n","resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.841509\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.843094\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.844663\n","resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.846217\n","CPU times: user 22min 2s, sys: 10min 1s, total: 32min 4s\n","Wall time: 16min 35s\n"]}],"source":["%time hist1 = train_model(env, model, total_episodes=500)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1069890,"status":"ok","timestamp":1660833249930,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"cHYCDYwhlVLV","outputId":"b56d47cd-f5db-434a-f86a-bb6c918dc95e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"name":"stdout","output_type":"stream","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 4.000000, reward total was -19.000000. running mean: -20.980000\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.980200\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.980398\n","resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.980594\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.980788\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.980980\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.981170\n","resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.971359\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.971645\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.971929\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.972209\n","resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.972487\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.972762\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.973035\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.973304\n","resetting env. episode 19.000000, reward total was -20.000000. running mean: -20.963571\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.963936\n","resetting env. episode 21.000000, reward total was -20.000000. running mean: -20.954296\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.954753\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.955206\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.955654\n","resetting env. episode 25.000000, reward total was -20.000000. running mean: -20.946097\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.946636\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.947170\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.947698\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.948221\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.948739\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.939252\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.939859\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.940460\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.941056\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.941645\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.942229\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.942807\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.943379\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.943945\n","resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.944505\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.945060\n","resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.945610\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.946154\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.946692\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.947225\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.947753\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.948275\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.948793\n","resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.949305\n","resetting env. episode 50.000000, reward total was -20.000000. running mean: -20.939812\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.940413\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.941009\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.941599\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.942183\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.942761\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.943334\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.943900\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.944461\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.945017\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.945567\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.946111\n","resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.936650\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.937283\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.937911\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.938531\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.939146\n","resetting env. episode 67.000000, reward total was -20.000000. running mean: -20.929755\n","resetting env. episode 68.000000, reward total was -20.000000. running mean: -20.920457\n","resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.911253\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.912140\n","resetting env. episode 71.000000, reward total was -19.000000. running mean: -20.893019\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.894088\n","resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.895148\n","resetting env. episode 74.000000, reward total was -19.000000. running mean: -20.876196\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.877434\n","resetting env. episode 76.000000, reward total was -20.000000. running mean: -20.868660\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.869973\n","resetting env. episode 78.000000, reward total was -20.000000. running mean: -20.861273\n","resetting env. episode 79.000000, reward total was -20.000000. running mean: -20.852661\n","resetting env. episode 80.000000, reward total was -18.000000. running mean: -20.824134\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.825893\n","resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.827634\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.829358\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.831064\n","resetting env. episode 85.000000, reward total was -20.000000. running mean: -20.822753\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.824526\n","resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.826281\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.828018\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.829738\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.831440\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.833126\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.834794\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.836447\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.838082\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.839701\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.841304\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.842891\n","resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.844462\n","resetting env. episode 99.000000, reward total was -20.000000. running mean: -20.836018\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.837657\n","resetting env. episode 101.000000, reward total was -20.000000. running mean: -20.829281\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.830988\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.832678\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.834351\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.836008\n","resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.837648\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.839271\n","resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.830879\n","resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.822570\n","resetting env. episode 110.000000, reward total was -20.000000. running mean: -20.814344\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.816201\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.818039\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.819858\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.821660\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.823443\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.825209\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.826957\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.828687\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.830400\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.832096\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.833775\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.835437\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.837083\n","resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.838712\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.840325\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.841922\n","resetting env. episode 127.000000, reward total was -20.000000. running mean: -20.833503\n","resetting env. episode 128.000000, reward total was -20.000000. running mean: -20.825168\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.826916\n","resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.828647\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.830360\n","resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.822057\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.823836\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.825598\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.827342\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.829068\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.830778\n","resetting env. episode 138.000000, reward total was -20.000000. running mean: -20.822470\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.824245\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.826003\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.827743\n","resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.829465\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.831171\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.832859\n","resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.824530\n","resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.826285\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.828022\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.829742\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.831445\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.833130\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.834799\n","resetting env. episode 152.000000, reward total was -20.000000. running mean: -20.826451\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.828186\n","resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.829904\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.831605\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.833289\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.834957\n","resetting env. episode 158.000000, reward total was -20.000000. running mean: -20.826607\n","resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.828341\n","resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.820057\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.821857\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.823638\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.825402\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.827148\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.828876\n","resetting env. episode 166.000000, reward total was -20.000000. running mean: -20.820588\n","resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.822382\n","resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.824158\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.825916\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.827657\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.829381\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.831087\n","resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.832776\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.834448\n","resetting env. episode 175.000000, reward total was -20.000000. running mean: -20.826104\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.827843\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.829564\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.831269\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.832956\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.834626\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.836280\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.837917\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.839538\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.841143\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.842731\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.844304\n","resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.835861\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.837502\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.839127\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.840736\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.842329\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.843905\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.845466\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.847012\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.848542\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.850056\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.851556\n","resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.853040\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.854510\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.855965\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.857405\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.858831\n","resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.860243\n","resetting env. episode 204.000000, reward total was -20.000000. running mean: -20.851640\n","resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.853124\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.854592\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.856047\n","resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.847486\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.849011\n","resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.850521\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.852016\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.853496\n","resetting env. episode 213.000000, reward total was -20.000000. running mean: -20.844961\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.846511\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.848046\n","resetting env. episode 216.000000, reward total was -19.000000. running mean: -20.829566\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.831270\n","resetting env. episode 218.000000, reward total was -20.000000. running mean: -20.822957\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.824728\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.826480\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.828216\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.829933\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.831634\n","resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.823318\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.825085\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.826834\n","resetting env. episode 227.000000, reward total was -20.000000. running mean: -20.818565\n","resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.820380\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.822176\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.823954\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.825715\n","resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.827458\n","resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.819183\n","resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.820991\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.822781\n","resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.824553\n","resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.826308\n","resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.828045\n","resetting env. episode 239.000000, reward total was -20.000000. running mean: -20.819764\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.821567\n","resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.813351\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.815218\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.817065\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.818895\n","resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.820706\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.822499\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.824274\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.826031\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.827771\n","resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.829493\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.831198\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.832886\n","resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.824557\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.826312\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.828048\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.829768\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.831470\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.833156\n","resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.824824\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.826576\n","resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.818310\n","resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.810127\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.812026\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.813905\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.815766\n","resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.817609\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.819433\n","resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.821238\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.823026\n","resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.824796\n","resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.816548\n","resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.818382\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.820198\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.821996\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.823776\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.825539\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.827283\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.829010\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.830720\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.832413\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.834089\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.835748\n","resetting env. episode 283.000000, reward total was -20.000000. running mean: -20.827391\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.829117\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.830826\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.832517\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.834192\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.835850\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.837492\n","resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.839117\n","resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.840726\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.832318\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.833995\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.835655\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.837299\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.838926\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.840536\n","resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.832131\n","resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.833810\n","resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.835472\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.837117\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.838746\n","resetting env. episode 303.000000, reward total was -20.000000. running mean: -20.830358\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.832055\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.833734\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.835397\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.837043\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.838672\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.840286\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.841883\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.843464\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.845029\n","resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.846579\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.848113\n","resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.849632\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.851136\n","resetting env. episode 317.000000, reward total was -20.000000. running mean: -20.842625\n","resetting env. episode 318.000000, reward total was -20.000000. running mean: -20.834198\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.835856\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.837498\n","resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.839123\n","resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.840732\n","resetting env. episode 323.000000, reward total was -20.000000. running mean: -20.832324\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.834001\n","resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.835661\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.837304\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.838931\n","resetting env. episode 328.000000, reward total was -20.000000. running mean: -20.830542\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.832237\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.833914\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.835575\n","resetting env. episode 332.000000, reward total was -20.000000. running mean: -20.827219\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.828947\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.830658\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.832351\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.834028\n","resetting env. episode 337.000000, reward total was -19.000000. running mean: -20.815687\n","resetting env. episode 338.000000, reward total was -19.000000. running mean: -20.797530\n","resetting env. episode 339.000000, reward total was -20.000000. running mean: -20.789555\n","resetting env. episode 340.000000, reward total was -18.000000. running mean: -20.761660\n","resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.764043\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.766403\n","resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.768739\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.771051\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.773341\n","resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.775607\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.777851\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.780073\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.782272\n","resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.784449\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.786605\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.788739\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.790851\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.792943\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.795013\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.797063\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.799093\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.801102\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.803091\n","resetting env. episode 360.000000, reward total was -19.000000. running mean: -20.785060\n","resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.777209\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.779437\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.781643\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.783826\n","resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.775988\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.778228\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.780446\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.782641\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.784815\n","resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.776967\n","resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.769197\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.771505\n","resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.773790\n","resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.776052\n","resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.778292\n","resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.780509\n","resetting env. episode 377.000000, reward total was -20.000000. running mean: -20.772704\n","resetting env. episode 378.000000, reward total was -19.000000. running mean: -20.754977\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.757427\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.759853\n","resetting env. episode 381.000000, reward total was -20.000000. running mean: -20.752254\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.754732\n","resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.757184\n","resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.749612\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.752116\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.754595\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.757049\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.759479\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.761884\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.764265\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.766622\n","resetting env. episode 392.000000, reward total was -20.000000. running mean: -20.758956\n","resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.761367\n","resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.753753\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.756215\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.758653\n","resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.751067\n","resetting env. episode 398.000000, reward total was -20.000000. running mean: -20.743556\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.746120\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.748659\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.751173\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.753661\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.756124\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.758563\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.760977\n","resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.753368\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.755834\n","resetting env. episode 408.000000, reward total was -20.000000. running mean: -20.748276\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.750793\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.753285\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.755752\n","resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.758195\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.760613\n","resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.763007\n","resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.755376\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.757823\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.760244\n","resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.752642\n","resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.745116\n","resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.747664\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.750188\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.752686\n","resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.755159\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.757607\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.760031\n","resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.752431\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.754907\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.757358\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.759784\n","resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.762186\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.764564\n","resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.766919\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.769250\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.771557\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.773842\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.776103\n","resetting env. episode 437.000000, reward total was -20.000000. running mean: -20.768342\n","resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.760659\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.763052\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.765422\n","resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.767767\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.770090\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.772389\n","resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.774665\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.776918\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.779149\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.781358\n","resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.783544\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.785709\n","resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.787851\n","resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.789973\n","resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.792073\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.794152\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.796211\n","resetting env. episode 455.000000, reward total was -20.000000. running mean: -20.788249\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.790366\n","resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.792463\n","resetting env. episode 458.000000, reward total was -20.000000. running mean: -20.784538\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.786693\n","resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.788826\n","resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.790938\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.793028\n","resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.795098\n","resetting env. episode 464.000000, reward total was -20.000000. running mean: -20.787147\n","resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.789275\n","resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.791383\n","resetting env. episode 467.000000, reward total was -20.000000. running mean: -20.783469\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.785634\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.787778\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.789900\n","resetting env. episode 471.000000, reward total was -20.000000. running mean: -20.782001\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.784181\n","resetting env. episode 473.000000, reward total was -20.000000. running mean: -20.776339\n","resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.778576\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.780790\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.782982\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.785152\n","resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.777301\n","resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.779528\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.781733\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.783915\n","resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.786076\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.788215\n","resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.790333\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.792430\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.794505\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.796560\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.798595\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.800609\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.802603\n","resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.804577\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.806531\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.808466\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.810381\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.812277\n","resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.814154\n","resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.816013\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.817853\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.819674\n","resetting env. episode 500.000000, reward total was -19.000000. running mean: -20.801478\n","CPU times: user 23min 41s, sys: 10min 45s, total: 34min 27s\n","Wall time: 17min 49s\n"]}],"source":["%time hist2 = train_model(env, model, total_episodes=500)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"elapsed":34916,"status":"ok","timestamp":1660833284840,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"8fheN9DRlWXQ","outputId":"3b5d4900-47b2-4bec-c2a9-067d1472ee2b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"name":"stdout","output_type":"stream","text":["Episode finished without success, accumulated reward = -7.0\n"]},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 320x420 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["play_game(env, model)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":296093,"status":"ok","timestamp":1660837422622,"user":{"displayName":"Abraham Chandy","userId":"13606766294498611725"},"user_tz":420},"id":"9AxOcQhIsKow"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"name":"stdout","output_type":"stream","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 4.000000, reward total was -20.000000. running mean: -20.980100\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.980299\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.980496\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.970691\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.970984\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.971274\n","resetting env. episode 10.000000, reward total was -20.000000. running mean: -20.961562\n","resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.961946\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.962326\n","resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.952703\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.953176\n","resetting env. episode 15.000000, reward total was -20.000000. running mean: -20.943644\n","resetting env. episode 16.000000, reward total was -19.000000. running mean: -20.924208\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.924966\n","resetting env. episode 18.000000, reward total was -20.000000. running mean: -20.915716\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.916559\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.917393\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.918220\n","resetting env. episode 22.000000, reward total was -20.000000. running mean: -20.909037\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.909947\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.910848\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.911739\n","resetting env. episode 26.000000, reward total was -20.000000. running mean: -20.902622\n","resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.893595\n","resetting env. episode 28.000000, reward total was -20.000000. running mean: -20.884659\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.885813\n","resetting env. episode 30.000000, reward total was -20.000000. running mean: -20.876955\n","resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.878185\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.879403\n","resetting env. episode 33.000000, reward total was -20.000000. running mean: -20.870609\n","resetting env. episode 34.000000, reward total was -20.000000. running mean: -20.861903\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.863284\n","resetting env. episode 36.000000, reward total was -20.000000. running mean: -20.854651\n","resetting env. episode 37.000000, reward total was -20.000000. running mean: -20.846105\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.847644\n","resetting env. episode 39.000000, reward total was -20.000000. running mean: -20.839167\n","resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.840776\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.842368\n","resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.833944\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.835605\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.837249\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.838876\n","resetting env. episode 46.000000, reward total was -20.000000. running mean: -20.830488\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.832183\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.833861\n","resetting env. episode 49.000000, reward total was -19.000000. running mean: -20.815522\n","resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.817367\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.819193\n","resetting env. episode 52.000000, reward total was -20.000000. running mean: -20.811001\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.812891\n","resetting env. episode 54.000000, reward total was -20.000000. running mean: -20.804762\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.806715\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.808648\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.810561\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.812456\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.814331\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.816188\n","resetting env. episode 61.000000, reward total was -20.000000. running mean: -20.808026\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.809946\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.811846\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.813728\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.815590\n","resetting env. episode 66.000000, reward total was -20.000000. running mean: -20.807434\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.809360\n","resetting env. episode 68.000000, reward total was -20.000000. running mean: -20.801267\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.803254\n","resetting env. episode 70.000000, reward total was -20.000000. running mean: -20.795221\n","resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.787269\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.789396\n","resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.781502\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.783687\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.785851\n","resetting env. episode 76.000000, reward total was -20.000000. running mean: -20.777992\n","resetting env. episode 77.000000, reward total was -20.000000. running mean: -20.770212\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.772510\n","resetting env. episode 79.000000, reward total was -19.000000. running mean: -20.754785\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.757237\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.759665\n","resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.762068\n","resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.754447\n","resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.746903\n","resetting env. episode 85.000000, reward total was -20.000000. running mean: -20.739434\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.742040\n","resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.744619\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.747173\n","resetting env. episode 89.000000, reward total was -20.000000. running mean: -20.739701\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.742304\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.744881\n","resetting env. episode 92.000000, reward total was -19.000000. running mean: -20.727432\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.730158\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.732856\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.735528\n","resetting env. episode 96.000000, reward total was -20.000000. running mean: -20.728173\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.730891\n","resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.733582\n","resetting env. episode 99.000000, reward total was -20.000000. running mean: -20.726246\n","resetting env. episode 100.000000, reward total was -20.000000. running mean: -20.718984\n","resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.721794\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.724576\n","resetting env. episode 103.000000, reward total was -20.000000. running mean: -20.717330\n","resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.710157\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.713055\n","resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.705925\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.708865\n","resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.701777\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.704759\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.707711\n","resetting env. episode 111.000000, reward total was -20.000000. running mean: -20.700634\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.703628\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.706592\n","resetting env. episode 114.000000, reward total was -20.000000. running mean: -20.699526\n","resetting env. episode 115.000000, reward total was -20.000000. running mean: -20.692531\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.695605\n","resetting env. episode 117.000000, reward total was -20.000000. running mean: -20.688649\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.691763\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.694845\n","resetting env. episode 120.000000, reward total was -20.000000. running mean: -20.687897\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.691018\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.694107\n","resetting env. episode 123.000000, reward total was -20.000000. running mean: -20.687166\n","resetting env. episode 124.000000, reward total was -18.000000. running mean: -20.660295\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.663692\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.667055\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.670384\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.673680\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.676944\n","resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.680174\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.683372\n","resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.676539\n","resetting env. episode 133.000000, reward total was -20.000000. running mean: -20.669773\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.673076\n","resetting env. episode 135.000000, reward total was -20.000000. running mean: -20.666345\n","resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.659681\n","resetting env. episode 137.000000, reward total was -19.000000. running mean: -20.643085\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.646654\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.650187\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.653685\n","resetting env. episode 141.000000, reward total was -20.000000. running mean: -20.647149\n","resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.650677\n","resetting env. episode 143.000000, reward total was -19.000000. running mean: -20.634170\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.637829\n","resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.641450\n","resetting env. episode 146.000000, reward total was -20.000000. running mean: -20.635036\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.638685\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.642299\n","resetting env. episode 149.000000, reward total was -19.000000. running mean: -20.625876\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.629617\n","resetting env. episode 151.000000, reward total was -20.000000. running mean: -20.623321\n","resetting env. episode 152.000000, reward total was -20.000000. running mean: -20.617087\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.620917\n","resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.614707\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.618560\n","resetting env. episode 156.000000, reward total was -20.000000. running mean: -20.612375\n","resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.606251\n","resetting env. episode 158.000000, reward total was -19.000000. running mean: -20.590188\n","resetting env. episode 159.000000, reward total was -19.000000. running mean: -20.574287\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.578544\n","resetting env. episode 161.000000, reward total was -20.000000. running mean: -20.572758\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.577031\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.581260\n","resetting env. episode 164.000000, reward total was -20.000000. running mean: -20.575448\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.579693\n","resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.583896\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.578057\n","resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.582277\n","resetting env. episode 169.000000, reward total was -17.000000. running mean: -20.546454\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.550990\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.555480\n","resetting env. episode 172.000000, reward total was -19.000000. running mean: -20.539925\n","resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.544526\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.549080\n","resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.553590\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.558054\n","resetting env. episode 177.000000, reward total was -19.000000. running mean: -20.542473\n","resetting env. episode 178.000000, reward total was -20.000000. running mean: -20.537048\n","resetting env. episode 179.000000, reward total was -17.000000. running mean: -20.501678\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.506661\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.511594\n","resetting env. episode 182.000000, reward total was -20.000000. running mean: -20.506479\n","resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.501414\n","resetting env. episode 184.000000, reward total was -20.000000. running mean: -20.496400\n","resetting env. episode 185.000000, reward total was -19.000000. running mean: -20.481436\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.486621\n","resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.491755\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.496838\n","resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.491869\n","resetting env. episode 190.000000, reward total was -20.000000. running mean: -20.486950\n","resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.482081\n","resetting env. episode 192.000000, reward total was -20.000000. running mean: -20.477260\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.482488\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.487663\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.492786\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.497858\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.502880\n","resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.497851\n","resetting env. episode 199.000000, reward total was -19.000000. running mean: -20.482872\n","resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.478044\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.483263\n","resetting env. episode 202.000000, reward total was -18.000000. running mean: -20.458430\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.453846\n","resetting env. episode 204.000000, reward total was -19.000000. running mean: -20.439308\n","resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.444915\n","resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.440466\n","resetting env. episode 207.000000, reward total was -19.000000. running mean: -20.426061\n","resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.421800\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.427582\n","resetting env. episode 210.000000, reward total was -19.000000. running mean: -20.413306\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.419173\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.424982\n","resetting env. episode 213.000000, reward total was -20.000000. running mean: -20.420732\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.426524\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.432259\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.437937\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.443557\n","resetting env. episode 218.000000, reward total was -19.000000. running mean: -20.429122\n","resetting env. episode 219.000000, reward total was -19.000000. running mean: -20.414830\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.420682\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.426475\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.432211\n","resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.427889\n","resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.423610\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.419374\n","resetting env. episode 226.000000, reward total was -20.000000. running mean: -20.415180\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.421028\n","resetting env. episode 228.000000, reward total was -19.000000. running mean: -20.406818\n","resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.402750\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.408722\n","resetting env. episode 231.000000, reward total was -17.000000. running mean: -20.374635\n","resetting env. episode 232.000000, reward total was -19.000000. running mean: -20.360888\n","resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.367280\n","resetting env. episode 234.000000, reward total was -19.000000. running mean: -20.353607\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.360071\n","resetting env. episode 236.000000, reward total was -20.000000. running mean: -20.356470\n","resetting env. episode 237.000000, reward total was -19.000000. running mean: -20.342905\n","resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.349476\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.355981\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.362422\n","resetting env. episode 241.000000, reward total was -19.000000. running mean: -20.348797\n","resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.345309\n","resetting env. episode 243.000000, reward total was -19.000000. running mean: -20.331856\n","resetting env. episode 244.000000, reward total was -19.000000. running mean: -20.318538\n","resetting env. episode 245.000000, reward total was -20.000000. running mean: -20.315352\n","resetting env. episode 246.000000, reward total was -18.000000. running mean: -20.292199\n","resetting env. episode 247.000000, reward total was -18.000000. running mean: -20.269277\n","resetting env. episode 248.000000, reward total was -18.000000. running mean: -20.246584\n","resetting env. episode 249.000000, reward total was -18.000000. running mean: -20.224118\n","resetting env. episode 250.000000, reward total was -19.000000. running mean: -20.211877\n","resetting env. episode 251.000000, reward total was -19.000000. running mean: -20.199758\n","resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.197761\n","resetting env. episode 253.000000, reward total was -19.000000. running mean: -20.185783\n","resetting env. episode 254.000000, reward total was -18.000000. running mean: -20.163925\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.172286\n","resetting env. episode 256.000000, reward total was -20.000000. running mean: -20.170563\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.178858\n","resetting env. episode 258.000000, reward total was -17.000000. running mean: -20.147069\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.155598\n","resetting env. episode 260.000000, reward total was -18.000000. running mean: -20.134042\n","resetting env. episode 261.000000, reward total was -17.000000. running mean: -20.102702\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.111675\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.120558\n","resetting env. episode 264.000000, reward total was -20.000000. running mean: -20.119353\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.128159\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.126877\n","resetting env. episode 267.000000, reward total was -20.000000. running mean: -20.125609\n","resetting env. episode 268.000000, reward total was -18.000000. running mean: -20.104353\n","resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.103309\n","resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.112276\n","resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.111153\n","resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.110042\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.118941\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.127752\n","resetting env. episode 275.000000, reward total was -18.000000. running mean: -20.106474\n","resetting env. episode 276.000000, reward total was -17.000000. running mean: -20.075410\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.084656\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.093809\n","resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.092871\n","resetting env. episode 280.000000, reward total was -20.000000. running mean: -20.091942\n","resetting env. episode 281.000000, reward total was -14.000000. running mean: -20.031023\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.040713\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.050305\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.059802\n","resetting env. episode 285.000000, reward total was -19.000000. running mean: -20.049204\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.058712\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.068125\n","resetting env. episode 288.000000, reward total was -19.000000. running mean: -20.057444\n","resetting env. episode 289.000000, reward total was -18.000000. running mean: -20.036869\n","resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.036501\n","resetting env. episode 291.000000, reward total was -19.000000. running mean: -20.026136\n","resetting env. episode 292.000000, reward total was -19.000000. running mean: -20.015874\n","resetting env. episode 293.000000, reward total was -19.000000. running mean: -20.005716\n","resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.005658\n","resetting env. episode 295.000000, reward total was -19.000000. running mean: -19.995602\n","resetting env. episode 296.000000, reward total was -18.000000. running mean: -19.975646\n","resetting env. episode 297.000000, reward total was -20.000000. running mean: -19.975889\n","resetting env. episode 298.000000, reward total was -20.000000. running mean: -19.976131\n","resetting env. episode 299.000000, reward total was -19.000000. running mean: -19.966369\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -19.966706\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -19.977038\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -19.987268\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -19.997395\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.007421\n","resetting env. episode 305.000000, reward total was -19.000000. running mean: -19.997347\n","resetting env. episode 306.000000, reward total was -19.000000. running mean: -19.987374\n","resetting env. episode 307.000000, reward total was -18.000000. running mean: -19.967500\n","resetting env. episode 308.000000, reward total was -18.000000. running mean: -19.947825\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -19.958347\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -19.968763\n","resetting env. episode 311.000000, reward total was -17.000000. running mean: -19.939076\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -19.949685\n","resetting env. episode 313.000000, reward total was -21.000000. running mean: -19.960188\n","resetting env. episode 314.000000, reward total was -20.000000. running mean: -19.960586\n","resetting env. episode 315.000000, reward total was -20.000000. running mean: -19.960980\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -19.971371\n","resetting env. episode 317.000000, reward total was -20.000000. running mean: -19.971657\n","resetting env. episode 318.000000, reward total was -21.000000. running mean: -19.981940\n","resetting env. episode 319.000000, reward total was -20.000000. running mean: -19.982121\n","resetting env. episode 320.000000, reward total was -19.000000. running mean: -19.972300\n","resetting env. episode 321.000000, reward total was -20.000000. running mean: -19.972577\n","resetting env. episode 322.000000, reward total was -20.000000. running mean: -19.972851\n","resetting env. episode 323.000000, reward total was -18.000000. running mean: -19.953122\n","resetting env. episode 324.000000, reward total was -19.000000. running mean: -19.943591\n","resetting env. episode 325.000000, reward total was -19.000000. running mean: -19.934155\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -19.944814\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -19.955366\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -19.965812\n","resetting env. episode 329.000000, reward total was -17.000000. running mean: -19.936154\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -19.946792\n","resetting env. episode 331.000000, reward total was -20.000000. running mean: -19.947324\n","resetting env. episode 332.000000, reward total was -17.000000. running mean: -19.917851\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -19.928673\n","resetting env. episode 334.000000, reward total was -17.000000. running mean: -19.899386\n","resetting env. episode 335.000000, reward total was -20.000000. running mean: -19.900392\n","resetting env. episode 336.000000, reward total was -20.000000. running mean: -19.901388\n","resetting env. episode 337.000000, reward total was -20.000000. running mean: -19.902374\n","resetting env. episode 338.000000, reward total was -20.000000. running mean: -19.903350\n","resetting env. episode 339.000000, reward total was -21.000000. running mean: -19.914317\n","resetting env. episode 340.000000, reward total was -18.000000. running mean: -19.895174\n","resetting env. episode 341.000000, reward total was -20.000000. running mean: -19.896222\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -19.907260\n","resetting env. episode 343.000000, reward total was -20.000000. running mean: -19.908187\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -19.919105\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -19.929914\n","resetting env. episode 346.000000, reward total was -20.000000. running mean: -19.930615\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -19.941309\n","resetting env. episode 348.000000, reward total was -20.000000. running mean: -19.941896\n","resetting env. episode 349.000000, reward total was -19.000000. running mean: -19.932477\n","resetting env. episode 350.000000, reward total was -21.000000. running mean: -19.943152\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -19.953721\n","resetting env. episode 352.000000, reward total was -20.000000. running mean: -19.954183\n","resetting env. episode 353.000000, reward total was -19.000000. running mean: -19.944642\n","resetting env. episode 354.000000, reward total was -18.000000. running mean: -19.925195\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -19.935943\n","resetting env. episode 356.000000, reward total was -20.000000. running mean: -19.936584\n","resetting env. episode 357.000000, reward total was -20.000000. running mean: -19.937218\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -19.947846\n","resetting env. episode 359.000000, reward total was -18.000000. running mean: -19.928367\n","resetting env. episode 360.000000, reward total was -20.000000. running mean: -19.929084\n","resetting env. episode 361.000000, reward total was -19.000000. running mean: -19.919793\n","resetting env. episode 362.000000, reward total was -20.000000. running mean: -19.920595\n","resetting env. episode 363.000000, reward total was -20.000000. running mean: -19.921389\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -19.932175\n","resetting env. episode 365.000000, reward total was -21.000000. running mean: -19.942853\n","resetting env. episode 366.000000, reward total was -19.000000. running mean: -19.933425\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -19.944091\n","resetting env. episode 368.000000, reward total was -20.000000. running mean: -19.944650\n","resetting env. episode 369.000000, reward total was -20.000000. running mean: -19.945203\n","resetting env. episode 370.000000, reward total was -21.000000. running mean: -19.955751\n","resetting env. episode 371.000000, reward total was -21.000000. running mean: -19.966194\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -19.976532\n","resetting env. episode 373.000000, reward total was -18.000000. running mean: -19.956766\n","resetting env. episode 374.000000, reward total was -19.000000. running mean: -19.947199\n","resetting env. episode 375.000000, reward total was -20.000000. running mean: -19.947727\n","resetting env. episode 376.000000, reward total was -17.000000. running mean: -19.918249\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -19.929067\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -19.939776\n","resetting env. episode 379.000000, reward total was -20.000000. running mean: -19.940378\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -19.950975\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -19.961465\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -19.971850\n","resetting env. episode 383.000000, reward total was -20.000000. running mean: -19.972132\n","resetting env. episode 384.000000, reward total was -21.000000. running mean: -19.982410\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -19.992586\n","resetting env. episode 386.000000, reward total was -18.000000. running mean: -19.972661\n","resetting env. episode 387.000000, reward total was -18.000000. running mean: -19.952934\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -19.963405\n","resetting env. episode 389.000000, reward total was -19.000000. running mean: -19.953771\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -19.964233\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -19.974590\n","resetting env. episode 392.000000, reward total was -18.000000. running mean: -19.954845\n","resetting env. episode 393.000000, reward total was -21.000000. running mean: -19.965296\n","resetting env. episode 394.000000, reward total was -21.000000. running mean: -19.975643\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -19.985887\n","resetting env. episode 396.000000, reward total was -20.000000. running mean: -19.986028\n","resetting env. episode 397.000000, reward total was -21.000000. running mean: -19.996168\n","resetting env. episode 398.000000, reward total was -20.000000. running mean: -19.996206\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.006244\n","resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.006181\n","resetting env. episode 401.000000, reward total was -20.000000. running mean: -20.006120\n","resetting env. episode 402.000000, reward total was -19.000000. running mean: -19.996058\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.006098\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.016037\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.025876\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.035618\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.045262\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.054809\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.064261\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.073618\n","resetting env. episode 411.000000, reward total was -20.000000. running mean: -20.072882\n","resetting env. episode 412.000000, reward total was -19.000000. running mean: -20.062153\n","resetting env. episode 413.000000, reward total was -20.000000. running mean: -20.061532\n","resetting env. episode 414.000000, reward total was -20.000000. running mean: -20.060916\n","resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.070307\n","resetting env. episode 416.000000, reward total was -19.000000. running mean: -20.059604\n","resetting env. episode 417.000000, reward total was -20.000000. running mean: -20.059008\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.068418\n","resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.067734\n","resetting env. episode 420.000000, reward total was -19.000000. running mean: -20.057056\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.066486\n","resetting env. episode 422.000000, reward total was -20.000000. running mean: -20.065821\n","resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.075163\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.084411\n","resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.083567\n","resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.082731\n","resetting env. episode 427.000000, reward total was -19.000000. running mean: -20.071904\n","resetting env. episode 428.000000, reward total was -20.000000. running mean: -20.071185\n","resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.070473\n","resetting env. episode 430.000000, reward total was -20.000000. running mean: -20.069769\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.079071\n","resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.078280\n","resetting env. episode 433.000000, reward total was -19.000000. running mean: -20.067497\n","resetting env. episode 434.000000, reward total was -20.000000. running mean: -20.066822\n","resetting env. episode 435.000000, reward total was -20.000000. running mean: -20.066154\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.075493\n","resetting env. episode 437.000000, reward total was -18.000000. running mean: -20.054738\n","resetting env. episode 438.000000, reward total was -19.000000. running mean: -20.044190\n","resetting env. episode 439.000000, reward total was -20.000000. running mean: -20.043748\n","resetting env. episode 440.000000, reward total was -16.000000. running mean: -20.003311\n","resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.003278\n","resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.003245\n","resetting env. episode 443.000000, reward total was -19.000000. running mean: -19.993213\n","resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.003280\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.013248\n","resetting env. episode 446.000000, reward total was -18.000000. running mean: -19.993115\n","resetting env. episode 447.000000, reward total was -20.000000. running mean: -19.993184\n","resetting env. episode 448.000000, reward total was -18.000000. running mean: -19.973252\n","resetting env. episode 449.000000, reward total was -20.000000. running mean: -19.973520\n","resetting env. episode 450.000000, reward total was -16.000000. running mean: -19.933784\n","resetting env. episode 451.000000, reward total was -20.000000. running mean: -19.934447\n","resetting env. episode 452.000000, reward total was -19.000000. running mean: -19.925102\n","resetting env. episode 453.000000, reward total was -19.000000. running mean: -19.915851\n","resetting env. episode 454.000000, reward total was -20.000000. running mean: -19.916693\n","resetting env. episode 455.000000, reward total was -20.000000. running mean: -19.917526\n","resetting env. episode 456.000000, reward total was -19.000000. running mean: -19.908350\n","resetting env. episode 457.000000, reward total was -19.000000. running mean: -19.899267\n","resetting env. episode 458.000000, reward total was -18.000000. running mean: -19.880274\n","resetting env. episode 459.000000, reward total was -20.000000. running mean: -19.881471\n","resetting env. episode 460.000000, reward total was -21.000000. running mean: -19.892657\n","resetting env. episode 461.000000, reward total was -16.000000. running mean: -19.853730\n","resetting env. episode 462.000000, reward total was -20.000000. running mean: -19.855193\n","resetting env. episode 463.000000, reward total was -21.000000. running mean: -19.866641\n","resetting env. episode 464.000000, reward total was -20.000000. running mean: -19.867975\n","resetting env. episode 465.000000, reward total was -20.000000. running mean: -19.869295\n","resetting env. episode 466.000000, reward total was -17.000000. running mean: -19.840602\n","resetting env. episode 467.000000, reward total was -20.000000. running mean: -19.842196\n","resetting env. episode 468.000000, reward total was -19.000000. running mean: -19.833774\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -19.845436\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -19.856982\n","resetting env. episode 471.000000, reward total was -20.000000. running mean: -19.858412\n","resetting env. episode 472.000000, reward total was -19.000000. running mean: -19.849828\n","resetting env. episode 473.000000, reward total was -19.000000. running mean: -19.841330\n","resetting env. episode 474.000000, reward total was -19.000000. running mean: -19.832916\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -19.844587\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -19.856141\n","resetting env. episode 477.000000, reward total was -18.000000. running mean: -19.837580\n","resetting env. episode 478.000000, reward total was -19.000000. running mean: -19.829204\n","resetting env. episode 479.000000, reward total was -19.000000. running mean: -19.820912\n","resetting env. episode 480.000000, reward total was -18.000000. running mean: -19.802703\n","resetting env. episode 481.000000, reward total was -20.000000. running mean: -19.804676\n","resetting env. episode 482.000000, reward total was -20.000000. running mean: -19.806629\n","resetting env. episode 483.000000, reward total was -20.000000. running mean: -19.808563\n","resetting env. episode 484.000000, reward total was -19.000000. running mean: -19.800477\n","resetting env. episode 485.000000, reward total was -20.000000. running mean: -19.802472\n","resetting env. episode 486.000000, reward total was -19.000000. running mean: -19.794448\n","resetting env. episode 487.000000, reward total was -18.000000. running mean: -19.776503\n","resetting env. episode 488.000000, reward total was -19.000000. running mean: -19.768738\n","resetting env. episode 489.000000, reward total was -17.000000. running mean: -19.741051\n","resetting env. episode 490.000000, reward total was -20.000000. running mean: -19.743640\n","resetting env. episode 491.000000, reward total was -19.000000. running mean: -19.736204\n","resetting env. episode 492.000000, reward total was -20.000000. running mean: -19.738842\n","resetting env. episode 493.000000, reward total was -20.000000. running mean: -19.741453\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -19.754039\n","resetting env. episode 495.000000, reward total was -20.000000. running mean: -19.756499\n","resetting env. episode 496.000000, reward total was -18.000000. running mean: -19.738934\n","resetting env. episode 497.000000, reward total was -20.000000. running mean: -19.741544\n","resetting env. episode 498.000000, reward total was -20.000000. running mean: -19.744129\n","resetting env. episode 499.000000, reward total was -18.000000. running mean: -19.726687\n","resetting env. episode 500.000000, reward total was -19.000000. running mean: -19.719421\n","resetting env. episode 501.000000, reward total was -20.000000. running mean: -19.722226\n","resetting env. episode 502.000000, reward total was -20.000000. running mean: -19.725004\n","resetting env. episode 503.000000, reward total was -20.000000. running mean: -19.727754\n","resetting env. episode 504.000000, reward total was -20.000000. running mean: -19.730477\n","resetting env. episode 505.000000, reward total was -21.000000. running mean: -19.743172\n","resetting env. episode 506.000000, reward total was -17.000000. running mean: -19.715740\n","resetting env. episode 507.000000, reward total was -21.000000. running mean: -19.728583\n","resetting env. episode 508.000000, reward total was -19.000000. running mean: -19.721297\n","resetting env. episode 509.000000, reward total was -20.000000. running mean: -19.724084\n","resetting env. episode 510.000000, reward total was -19.000000. running mean: -19.716843\n","resetting env. episode 511.000000, reward total was -19.000000. running mean: -19.709675\n","resetting env. episode 512.000000, reward total was -20.000000. running mean: -19.712578\n","resetting env. episode 513.000000, reward total was -18.000000. running mean: -19.695452\n","resetting env. episode 514.000000, reward total was -19.000000. running mean: -19.688498\n","resetting env. episode 515.000000, reward total was -21.000000. running mean: -19.701613\n","resetting env. episode 516.000000, reward total was -20.000000. running mean: -19.704596\n","resetting env. episode 517.000000, reward total was -18.000000. running mean: -19.687550\n","resetting env. episode 518.000000, reward total was -18.000000. running mean: -19.670675\n","resetting env. episode 519.000000, reward total was -20.000000. running mean: -19.673968\n","resetting env. episode 520.000000, reward total was -19.000000. running mean: -19.667229\n","resetting env. episode 521.000000, reward total was -19.000000. running mean: -19.660556\n","resetting env. episode 522.000000, reward total was -18.000000. running mean: -19.643951\n","resetting env. episode 523.000000, reward total was -19.000000. running mean: -19.637511\n","resetting env. episode 524.000000, reward total was -19.000000. running mean: -19.631136\n","resetting env. episode 525.000000, reward total was -20.000000. running mean: -19.634825\n","resetting env. episode 526.000000, reward total was -18.000000. running mean: -19.618476\n","resetting env. episode 527.000000, reward total was -21.000000. running mean: -19.632292\n","resetting env. episode 528.000000, reward total was -19.000000. running mean: -19.625969\n","resetting env. episode 529.000000, reward total was -16.000000. running mean: -19.589709\n","resetting env. episode 530.000000, reward total was -17.000000. running mean: -19.563812\n","resetting env. episode 531.000000, reward total was -21.000000. running mean: -19.578174\n","resetting env. episode 532.000000, reward total was -18.000000. running mean: -19.562392\n","resetting env. episode 533.000000, reward total was -18.000000. running mean: -19.546768\n","resetting env. episode 534.000000, reward total was -15.000000. running mean: -19.501301\n","resetting env. episode 535.000000, reward total was -21.000000. running mean: -19.516288\n","resetting env. episode 536.000000, reward total was -20.000000. running mean: -19.521125\n","resetting env. episode 537.000000, reward total was -19.000000. running mean: -19.515913\n","resetting env. episode 538.000000, reward total was -18.000000. running mean: -19.500754\n","resetting env. episode 539.000000, reward total was -21.000000. running mean: -19.515747\n","resetting env. episode 540.000000, reward total was -19.000000. running mean: -19.510589\n","resetting env. episode 541.000000, reward total was -21.000000. running mean: -19.525483\n","resetting env. episode 542.000000, reward total was -21.000000. running mean: -19.540229\n","resetting env. episode 543.000000, reward total was -21.000000. running mean: -19.554826\n","resetting env. episode 544.000000, reward total was -21.000000. running mean: -19.569278\n","resetting env. episode 545.000000, reward total was -21.000000. running mean: -19.583585\n","resetting env. episode 546.000000, reward total was -21.000000. running mean: -19.597749\n","resetting env. episode 547.000000, reward total was -21.000000. running mean: -19.611772\n","resetting env. episode 548.000000, reward total was -19.000000. running mean: -19.605654\n","resetting env. episode 549.000000, reward total was -21.000000. running mean: -19.619598\n","resetting env. episode 550.000000, reward total was -21.000000. running mean: -19.633402\n","resetting env. episode 551.000000, reward total was -21.000000. running mean: -19.647068\n","resetting env. episode 552.000000, reward total was -21.000000. running mean: -19.660597\n","resetting env. episode 553.000000, reward total was -21.000000. running mean: -19.673991\n","resetting env. episode 554.000000, reward total was -21.000000. running mean: -19.687251\n","resetting env. episode 555.000000, reward total was -19.000000. running mean: -19.680379\n","resetting env. episode 556.000000, reward total was -21.000000. running mean: -19.693575\n","resetting env. episode 557.000000, reward total was -20.000000. running mean: -19.696639\n","resetting env. episode 558.000000, reward total was -21.000000. running mean: -19.709673\n","resetting env. episode 559.000000, reward total was -21.000000. running mean: -19.722576\n","resetting env. episode 560.000000, reward total was -21.000000. running mean: -19.735350\n","resetting env. episode 561.000000, reward total was -21.000000. running mean: -19.747997\n","resetting env. episode 562.000000, reward total was -21.000000. running mean: -19.760517\n","resetting env. episode 563.000000, reward total was -21.000000. running mean: -19.772912\n","resetting env. episode 564.000000, reward total was -21.000000. running mean: -19.785182\n","resetting env. episode 565.000000, reward total was -21.000000. running mean: -19.797331\n","resetting env. episode 566.000000, reward total was -21.000000. running mean: -19.809357\n","resetting env. episode 567.000000, reward total was -20.000000. running mean: -19.811264\n","resetting env. episode 568.000000, reward total was -21.000000. running mean: -19.823151\n","resetting env. episode 569.000000, reward total was -17.000000. running mean: -19.794920\n","resetting env. episode 570.000000, reward total was -20.000000. running mean: -19.796970\n","resetting env. episode 571.000000, reward total was -19.000000. running mean: -19.789001\n","resetting env. episode 572.000000, reward total was -21.000000. running mean: -19.801111\n","resetting env. episode 573.000000, reward total was -19.000000. running mean: -19.793100\n","resetting env. episode 574.000000, reward total was -21.000000. running mean: -19.805169\n","resetting env. episode 575.000000, reward total was -20.000000. running mean: -19.807117\n","resetting env. episode 576.000000, reward total was -21.000000. running mean: -19.819046\n","resetting env. episode 577.000000, reward total was -21.000000. running mean: -19.830855\n","resetting env. episode 578.000000, reward total was -21.000000. running mean: -19.842547\n","resetting env. episode 579.000000, reward total was -21.000000. running mean: -19.854121\n","resetting env. episode 580.000000, reward total was -16.000000. running mean: -19.815580\n","resetting env. episode 581.000000, reward total was -17.000000. running mean: -19.787424\n","resetting env. episode 582.000000, reward total was -18.000000. running mean: -19.769550\n","resetting env. episode 583.000000, reward total was -20.000000. running mean: -19.771854\n","resetting env. episode 584.000000, reward total was -18.000000. running mean: -19.754136\n","resetting env. episode 585.000000, reward total was -21.000000. running mean: -19.766595\n","resetting env. episode 586.000000, reward total was -21.000000. running mean: -19.778929\n","resetting env. episode 587.000000, reward total was -21.000000. running mean: -19.791139\n","resetting env. episode 588.000000, reward total was -20.000000. running mean: -19.793228\n","resetting env. episode 589.000000, reward total was -20.000000. running mean: -19.795296\n","resetting env. episode 590.000000, reward total was -17.000000. running mean: -19.767343\n","resetting env. episode 591.000000, reward total was -21.000000. running mean: -19.779669\n","resetting env. episode 592.000000, reward total was -21.000000. running mean: -19.791873\n","resetting env. episode 593.000000, reward total was -21.000000. running mean: -19.803954\n","resetting env. episode 594.000000, reward total was -20.000000. running mean: -19.805914\n","resetting env. episode 595.000000, reward total was -20.000000. running mean: -19.807855\n","resetting env. episode 596.000000, reward total was -19.000000. running mean: -19.799777\n","resetting env. episode 597.000000, reward total was -19.000000. running mean: -19.791779\n","resetting env. episode 598.000000, reward total was -20.000000. running mean: -19.793861\n","resetting env. episode 599.000000, reward total was -20.000000. running mean: -19.795922\n","resetting env. episode 600.000000, reward total was -19.000000. running mean: -19.787963\n","resetting env. episode 601.000000, reward total was -21.000000. running mean: -19.800084\n","resetting env. episode 602.000000, reward total was -18.000000. running mean: -19.782083\n","resetting env. episode 603.000000, reward total was -19.000000. running mean: -19.774262\n","resetting env. episode 604.000000, reward total was -17.000000. running mean: -19.746519\n","resetting env. episode 605.000000, reward total was -17.000000. running mean: -19.719054\n","resetting env. episode 606.000000, reward total was -17.000000. running mean: -19.691864\n","resetting env. episode 607.000000, reward total was -20.000000. running mean: -19.694945\n","resetting env. episode 608.000000, reward total was -21.000000. running mean: -19.707995\n","resetting env. episode 609.000000, reward total was -18.000000. running mean: -19.690916\n","resetting env. episode 610.000000, reward total was -20.000000. running mean: -19.694006\n","resetting env. episode 611.000000, reward total was -14.000000. running mean: -19.637066\n","resetting env. episode 612.000000, reward total was -19.000000. running mean: -19.630696\n","resetting env. episode 613.000000, reward total was -18.000000. running mean: -19.614389\n","resetting env. episode 614.000000, reward total was -17.000000. running mean: -19.588245\n","resetting env. episode 615.000000, reward total was -21.000000. running mean: -19.602362\n","resetting env. episode 616.000000, reward total was -20.000000. running mean: -19.606339\n","resetting env. episode 617.000000, reward total was -21.000000. running mean: -19.620275\n","resetting env. episode 618.000000, reward total was -21.000000. running mean: -19.634073\n","resetting env. episode 619.000000, reward total was -21.000000. running mean: -19.647732\n","resetting env. episode 620.000000, reward total was -21.000000. running mean: -19.661255\n","resetting env. episode 621.000000, reward total was -21.000000. running mean: -19.674642\n","resetting env. episode 622.000000, reward total was -19.000000. running mean: -19.667896\n","resetting env. episode 623.000000, reward total was -21.000000. running mean: -19.681217\n","resetting env. episode 624.000000, reward total was -21.000000. running mean: -19.694404\n","resetting env. episode 625.000000, reward total was -21.000000. running mean: -19.707460\n","resetting env. episode 626.000000, reward total was -21.000000. running mean: -19.720386\n","resetting env. episode 627.000000, reward total was -21.000000. running mean: -19.733182\n","resetting env. episode 628.000000, reward total was -19.000000. running mean: -19.725850\n","resetting env. episode 629.000000, reward total was -21.000000. running mean: -19.738592\n","resetting env. episode 630.000000, reward total was -21.000000. running mean: -19.751206\n","resetting env. episode 631.000000, reward total was -19.000000. running mean: -19.743694\n","resetting env. episode 632.000000, reward total was -21.000000. running mean: -19.756257\n","resetting env. episode 633.000000, reward total was -21.000000. running mean: -19.768694\n","resetting env. episode 634.000000, reward total was -21.000000. running mean: -19.781007\n","resetting env. episode 635.000000, reward total was -21.000000. running mean: -19.793197\n","resetting env. episode 636.000000, reward total was -17.000000. running mean: -19.765265\n","resetting env. episode 637.000000, reward total was -20.000000. running mean: -19.767613\n","resetting env. episode 638.000000, reward total was -21.000000. running mean: -19.779936\n","resetting env. episode 639.000000, reward total was -19.000000. running mean: -19.772137\n","resetting env. episode 640.000000, reward total was -21.000000. running mean: -19.784416\n","resetting env. episode 641.000000, reward total was -21.000000. running mean: -19.796572\n","resetting env. episode 642.000000, reward total was -21.000000. running mean: -19.808606\n","resetting env. episode 643.000000, reward total was -19.000000. running mean: -19.800520\n","resetting env. episode 644.000000, reward total was -19.000000. running mean: -19.792515\n","resetting env. episode 645.000000, reward total was -21.000000. running mean: -19.804589\n","resetting env. episode 646.000000, reward total was -21.000000. running mean: -19.816543\n","resetting env. episode 647.000000, reward total was -21.000000. running mean: -19.828378\n","resetting env. episode 648.000000, reward total was -21.000000. running mean: -19.840094\n","resetting env. episode 649.000000, reward total was -21.000000. running mean: -19.851693\n","resetting env. episode 650.000000, reward total was -21.000000. running mean: -19.863176\n","resetting env. episode 651.000000, reward total was -21.000000. running mean: -19.874545\n","resetting env. episode 652.000000, reward total was -21.000000. running mean: -19.885799\n","resetting env. episode 653.000000, reward total was -19.000000. running mean: -19.876941\n","resetting env. episode 654.000000, reward total was -21.000000. running mean: -19.888172\n","resetting env. episode 655.000000, reward total was -17.000000. running mean: -19.859290\n","resetting env. episode 656.000000, reward total was -19.000000. running mean: -19.850697\n","resetting env. episode 657.000000, reward total was -21.000000. running mean: -19.862190\n","resetting env. episode 658.000000, reward total was -20.000000. running mean: -19.863568\n","resetting env. episode 659.000000, reward total was -19.000000. running mean: -19.854933\n","resetting env. episode 660.000000, reward total was -21.000000. running mean: -19.866383\n","resetting env. episode 661.000000, reward total was -21.000000. running mean: -19.877719\n","resetting env. episode 662.000000, reward total was -21.000000. running mean: -19.888942\n","resetting env. episode 663.000000, reward total was -21.000000. running mean: -19.900053\n","resetting env. episode 664.000000, reward total was -21.000000. running mean: -19.911052\n","resetting env. episode 665.000000, reward total was -20.000000. running mean: -19.911942\n","resetting env. episode 666.000000, reward total was -21.000000. running mean: -19.922822\n","resetting env. episode 667.000000, reward total was -21.000000. running mean: -19.933594\n","resetting env. episode 668.000000, reward total was -21.000000. running mean: -19.944258\n","resetting env. episode 669.000000, reward total was -21.000000. running mean: -19.954816\n","resetting env. episode 670.000000, reward total was -21.000000. running mean: -19.965267\n","resetting env. episode 671.000000, reward total was -19.000000. running mean: -19.955615\n","resetting env. episode 672.000000, reward total was -20.000000. running mean: -19.956059\n","resetting env. episode 673.000000, reward total was -21.000000. running mean: -19.966498\n","resetting env. episode 674.000000, reward total was -21.000000. running mean: -19.976833\n","resetting env. episode 675.000000, reward total was -21.000000. running mean: -19.987065\n","resetting env. episode 676.000000, reward total was -21.000000. running mean: -19.997194\n","resetting env. episode 677.000000, reward total was -21.000000. running mean: -20.007222\n","resetting env. episode 678.000000, reward total was -18.000000. running mean: -19.987150\n","resetting env. episode 679.000000, reward total was -21.000000. running mean: -19.997278\n","resetting env. episode 680.000000, reward total was -21.000000. running mean: -20.007306\n","resetting env. episode 681.000000, reward total was -20.000000. running mean: -20.007233\n","resetting env. episode 682.000000, reward total was -21.000000. running mean: -20.017160\n","resetting env. episode 683.000000, reward total was -20.000000. running mean: -20.016989\n","resetting env. episode 684.000000, reward total was -21.000000. running mean: -20.026819\n","resetting env. episode 685.000000, reward total was -21.000000. running mean: -20.036551\n","resetting env. episode 686.000000, reward total was -21.000000. running mean: -20.046185\n","resetting env. episode 687.000000, reward total was -21.000000. running mean: -20.055723\n","resetting env. episode 688.000000, reward total was -20.000000. running mean: -20.055166\n","resetting env. episode 689.000000, reward total was -18.000000. running mean: -20.034614\n","resetting env. episode 690.000000, reward total was -20.000000. running mean: -20.034268\n","resetting env. episode 691.000000, reward total was -21.000000. running mean: -20.043926\n","resetting env. episode 692.000000, reward total was -21.000000. running mean: -20.053486\n","resetting env. episode 693.000000, reward total was -21.000000. running mean: -20.062951\n","resetting env. episode 694.000000, reward total was -21.000000. running mean: -20.072322\n","resetting env. episode 695.000000, reward total was -21.000000. running mean: -20.081599\n","resetting env. episode 696.000000, reward total was -21.000000. running mean: -20.090783\n","resetting env. episode 697.000000, reward total was -20.000000. running mean: -20.089875\n","resetting env. episode 698.000000, reward total was -21.000000. running mean: -20.098976\n","resetting env. episode 699.000000, reward total was -21.000000. running mean: -20.107986\n","resetting env. episode 700.000000, reward total was -21.000000. running mean: -20.116906\n","resetting env. episode 701.000000, reward total was -21.000000. running mean: -20.125737\n","resetting env. episode 702.000000, reward total was -21.000000. running mean: -20.134480\n","resetting env. episode 703.000000, reward total was -19.000000. running mean: -20.123135\n","resetting env. episode 704.000000, reward total was -18.000000. running mean: -20.101904\n","resetting env. episode 705.000000, reward total was -20.000000. running mean: -20.100885\n","resetting env. episode 706.000000, reward total was -21.000000. running mean: -20.109876\n","resetting env. episode 707.000000, reward total was -21.000000. running mean: -20.118777\n","resetting env. episode 708.000000, reward total was -20.000000. running mean: -20.117589\n","resetting env. episode 709.000000, reward total was -19.000000. running mean: -20.106414\n","resetting env. episode 710.000000, reward total was -19.000000. running mean: -20.095349\n","resetting env. episode 711.000000, reward total was -18.000000. running mean: -20.074396\n","resetting env. episode 712.000000, reward total was -17.000000. running mean: -20.043652\n","resetting env. episode 713.000000, reward total was -19.000000. running mean: -20.033215\n","resetting env. episode 714.000000, reward total was -21.000000. running mean: -20.042883\n","resetting env. episode 715.000000, reward total was -19.000000. running mean: -20.032454\n","resetting env. episode 716.000000, reward total was -18.000000. running mean: -20.012130\n","resetting env. episode 717.000000, reward total was -20.000000. running mean: -20.012009\n","resetting env. episode 718.000000, reward total was -21.000000. running mean: -20.021889\n","resetting env. episode 719.000000, reward total was -16.000000. running mean: -19.981670\n","resetting env. episode 720.000000, reward total was -20.000000. running mean: -19.981853\n","resetting env. episode 721.000000, reward total was -21.000000. running mean: -19.992034\n","resetting env. episode 722.000000, reward total was -17.000000. running mean: -19.962114\n","resetting env. episode 723.000000, reward total was -14.000000. running mean: -19.902493\n","resetting env. episode 724.000000, reward total was -20.000000. running mean: -19.903468\n","resetting env. episode 725.000000, reward total was -21.000000. running mean: -19.914433\n","resetting env. episode 726.000000, reward total was -21.000000. running mean: -19.925289\n","resetting env. episode 727.000000, reward total was -18.000000. running mean: -19.906036\n","resetting env. episode 728.000000, reward total was -19.000000. running mean: -19.896976\n","resetting env. episode 729.000000, reward total was -19.000000. running mean: -19.888006\n","resetting env. episode 730.000000, reward total was -20.000000. running mean: -19.889126\n","resetting env. episode 731.000000, reward total was -20.000000. running mean: -19.890235\n","resetting env. episode 732.000000, reward total was -18.000000. running mean: -19.871332\n","resetting env. episode 733.000000, reward total was -18.000000. running mean: -19.852619\n","resetting env. episode 734.000000, reward total was -19.000000. running mean: -19.844093\n","resetting env. episode 735.000000, reward total was -18.000000. running mean: -19.825652\n","resetting env. episode 736.000000, reward total was -20.000000. running mean: -19.827395\n","resetting env. episode 737.000000, reward total was -21.000000. running mean: -19.839121\n","resetting env. episode 738.000000, reward total was -20.000000. running mean: -19.840730\n","resetting env. episode 739.000000, reward total was -19.000000. running mean: -19.832323\n","resetting env. episode 740.000000, reward total was -18.000000. running mean: -19.814000\n","resetting env. episode 741.000000, reward total was -21.000000. running mean: -19.825860\n","resetting env. episode 742.000000, reward total was -20.000000. running mean: -19.827601\n","resetting env. episode 743.000000, reward total was -20.000000. running mean: -19.829325\n","resetting env. episode 744.000000, reward total was -20.000000. running mean: -19.831032\n","resetting env. episode 745.000000, reward total was -21.000000. running mean: -19.842721\n","resetting env. episode 746.000000, reward total was -19.000000. running mean: -19.834294\n","resetting env. episode 747.000000, reward total was -19.000000. running mean: -19.825951\n","resetting env. episode 748.000000, reward total was -18.000000. running mean: -19.807692\n","resetting env. episode 749.000000, reward total was -15.000000. running mean: -19.759615\n","resetting env. episode 750.000000, reward total was -19.000000. running mean: -19.752019\n","resetting env. episode 751.000000, reward total was -18.000000. running mean: -19.734499\n","resetting env. episode 752.000000, reward total was -20.000000. running mean: -19.737154\n","resetting env. episode 753.000000, reward total was -21.000000. running mean: -19.749782\n","resetting env. episode 754.000000, reward total was -19.000000. running mean: -19.742284\n","resetting env. episode 755.000000, reward total was -17.000000. running mean: -19.714861\n","resetting env. episode 756.000000, reward total was -20.000000. running mean: -19.717713\n","resetting env. episode 757.000000, reward total was -21.000000. running mean: -19.730536\n","resetting env. episode 758.000000, reward total was -21.000000. running mean: -19.743230\n","resetting env. episode 759.000000, reward total was -20.000000. running mean: -19.745798\n","resetting env. episode 760.000000, reward total was -17.000000. running mean: -19.718340\n","resetting env. episode 761.000000, reward total was -20.000000. running mean: -19.721157\n","resetting env. episode 762.000000, reward total was -20.000000. running mean: -19.723945\n","resetting env. episode 763.000000, reward total was -21.000000. running mean: -19.736706\n","resetting env. episode 764.000000, reward total was -20.000000. running mean: -19.739339\n","resetting env. episode 765.000000, reward total was -19.000000. running mean: -19.731945\n","resetting env. episode 766.000000, reward total was -18.000000. running mean: -19.714626\n","resetting env. episode 767.000000, reward total was -21.000000. running mean: -19.727479\n","resetting env. episode 768.000000, reward total was -19.000000. running mean: -19.720205\n","resetting env. episode 769.000000, reward total was -21.000000. running mean: -19.733003\n","resetting env. episode 770.000000, reward total was -20.000000. running mean: -19.735673\n","resetting env. episode 771.000000, reward total was -21.000000. running mean: -19.748316\n","resetting env. episode 772.000000, reward total was -21.000000. running mean: -19.760833\n","resetting env. episode 773.000000, reward total was -21.000000. running mean: -19.773224\n","resetting env. episode 774.000000, reward total was -20.000000. running mean: -19.775492\n","resetting env. episode 775.000000, reward total was -21.000000. running mean: -19.787737\n","resetting env. episode 776.000000, reward total was -19.000000. running mean: -19.779860\n","resetting env. episode 777.000000, reward total was -21.000000. running mean: -19.792061\n","resetting env. episode 778.000000, reward total was -20.000000. running mean: -19.794141\n","resetting env. episode 779.000000, reward total was -20.000000. running mean: -19.796199\n","resetting env. episode 780.000000, reward total was -20.000000. running mean: -19.798237\n","resetting env. episode 781.000000, reward total was -20.000000. running mean: -19.800255\n","resetting env. episode 782.000000, reward total was -20.000000. running mean: -19.802252\n","resetting env. episode 783.000000, reward total was -18.000000. running mean: -19.784230\n","resetting env. episode 784.000000, reward total was -20.000000. running mean: -19.786387\n","resetting env. episode 785.000000, reward total was -18.000000. running mean: -19.768524\n","resetting env. episode 786.000000, reward total was -20.000000. running mean: -19.770838\n","resetting env. episode 787.000000, reward total was -17.000000. running mean: -19.743130\n","resetting env. episode 788.000000, reward total was -20.000000. running mean: -19.745699\n","resetting env. episode 789.000000, reward total was -17.000000. running mean: -19.718242\n","resetting env. episode 790.000000, reward total was -18.000000. running mean: -19.701059\n","resetting env. episode 791.000000, reward total was -21.000000. running mean: -19.714049\n","resetting env. episode 792.000000, reward total was -19.000000. running mean: -19.706908\n","resetting env. episode 793.000000, reward total was -21.000000. running mean: -19.719839\n","resetting env. episode 794.000000, reward total was -19.000000. running mean: -19.712641\n","resetting env. episode 795.000000, reward total was -20.000000. running mean: -19.715514\n","resetting env. episode 796.000000, reward total was -20.000000. running mean: -19.718359\n","resetting env. episode 797.000000, reward total was -21.000000. running mean: -19.731176\n","resetting env. episode 798.000000, reward total was -19.000000. running mean: -19.723864\n","resetting env. episode 799.000000, reward total was -20.000000. running mean: -19.726625\n","resetting env. episode 800.000000, reward total was -21.000000. running mean: -19.739359\n","resetting env. episode 801.000000, reward total was -19.000000. running mean: -19.731965\n","resetting env. episode 802.000000, reward total was -20.000000. running mean: -19.734646\n","resetting env. episode 803.000000, reward total was -21.000000. running mean: -19.747299\n","resetting env. episode 804.000000, reward total was -21.000000. running mean: -19.759826\n","resetting env. episode 805.000000, reward total was -21.000000. running mean: -19.772228\n","resetting env. episode 806.000000, reward total was -17.000000. running mean: -19.744506\n","resetting env. episode 807.000000, reward total was -21.000000. running mean: -19.757061\n","resetting env. episode 808.000000, reward total was -21.000000. running mean: -19.769490\n","resetting env. episode 809.000000, reward total was -18.000000. running mean: -19.751795\n","resetting env. episode 810.000000, reward total was -21.000000. running mean: -19.764277\n","resetting env. episode 811.000000, reward total was -18.000000. running mean: -19.746634\n","resetting env. episode 812.000000, reward total was -18.000000. running mean: -19.729168\n","resetting env. episode 813.000000, reward total was -21.000000. running mean: -19.741876\n","resetting env. episode 814.000000, reward total was -20.000000. running mean: -19.744458\n","resetting env. episode 815.000000, reward total was -19.000000. running mean: -19.737013\n","resetting env. episode 816.000000, reward total was -21.000000. running mean: -19.749643\n","resetting env. episode 817.000000, reward total was -18.000000. running mean: -19.732146\n","resetting env. episode 818.000000, reward total was -20.000000. running mean: -19.734825\n","resetting env. episode 819.000000, reward total was -20.000000. running mean: -19.737477\n","resetting env. episode 820.000000, reward total was -20.000000. running mean: -19.740102\n","resetting env. episode 821.000000, reward total was -20.000000. running mean: -19.742701\n","resetting env. episode 822.000000, reward total was -19.000000. running mean: -19.735274\n","resetting env. episode 823.000000, reward total was -19.000000. running mean: -19.727921\n","resetting env. episode 824.000000, reward total was -20.000000. running mean: -19.730642\n","resetting env. episode 825.000000, reward total was -21.000000. running mean: -19.743336\n","resetting env. episode 826.000000, reward total was -20.000000. running mean: -19.745902\n","resetting env. episode 827.000000, reward total was -20.000000. running mean: -19.748443\n","resetting env. episode 828.000000, reward total was -20.000000. running mean: -19.750959\n","resetting env. episode 829.000000, reward total was -20.000000. running mean: -19.753449\n","resetting env. episode 830.000000, reward total was -20.000000. running mean: -19.755915\n","resetting env. episode 831.000000, reward total was -20.000000. running mean: -19.758356\n","resetting env. episode 832.000000, reward total was -18.000000. running mean: -19.740772\n","resetting env. episode 833.000000, reward total was -19.000000. running mean: -19.733364\n","resetting env. episode 834.000000, reward total was -18.000000. running mean: -19.716031\n","resetting env. episode 835.000000, reward total was -20.000000. running mean: -19.718870\n","resetting env. episode 836.000000, reward total was -21.000000. running mean: -19.731682\n","resetting env. episode 837.000000, reward total was -21.000000. running mean: -19.744365\n","resetting env. episode 838.000000, reward total was -20.000000. running mean: -19.746921\n","resetting env. episode 839.000000, reward total was -20.000000. running mean: -19.749452\n","resetting env. episode 840.000000, reward total was -19.000000. running mean: -19.741957\n","resetting env. episode 841.000000, reward total was -20.000000. running mean: -19.744538\n","resetting env. episode 842.000000, reward total was -19.000000. running mean: -19.737092\n","resetting env. episode 843.000000, reward total was -20.000000. running mean: -19.739722\n","resetting env. episode 844.000000, reward total was -21.000000. running mean: -19.752324\n","resetting env. episode 845.000000, reward total was -20.000000. running mean: -19.754801\n","resetting env. episode 846.000000, reward total was -21.000000. running mean: -19.767253\n","resetting env. episode 847.000000, reward total was -19.000000. running mean: -19.759581\n","resetting env. episode 848.000000, reward total was -18.000000. running mean: -19.741985\n","resetting env. episode 849.000000, reward total was -19.000000. running mean: -19.734565\n","resetting env. episode 850.000000, reward total was -20.000000. running mean: -19.737219\n","resetting env. episode 851.000000, reward total was -20.000000. running mean: -19.739847\n","resetting env. episode 852.000000, reward total was -20.000000. running mean: -19.742449\n","resetting env. episode 853.000000, reward total was -17.000000. running mean: -19.715024\n","resetting env. episode 854.000000, reward total was -20.000000. running mean: -19.717874\n","resetting env. episode 855.000000, reward total was -18.000000. running mean: -19.700695\n","resetting env. episode 856.000000, reward total was -21.000000. running mean: -19.713688\n","resetting env. episode 857.000000, reward total was -18.000000. running mean: -19.696551\n","resetting env. episode 858.000000, reward total was -21.000000. running mean: -19.709586\n","resetting env. episode 859.000000, reward total was -20.000000. running mean: -19.712490\n","resetting env. episode 860.000000, reward total was -20.000000. running mean: -19.715365\n","resetting env. episode 861.000000, reward total was -20.000000. running mean: -19.718211\n","resetting env. episode 862.000000, reward total was -18.000000. running mean: -19.701029\n","resetting env. episode 863.000000, reward total was -20.000000. running mean: -19.704019\n","resetting env. episode 864.000000, reward total was -19.000000. running mean: -19.696979\n","resetting env. episode 865.000000, reward total was -19.000000. running mean: -19.690009\n","resetting env. episode 866.000000, reward total was -20.000000. running mean: -19.693109\n","resetting env. episode 867.000000, reward total was -19.000000. running mean: -19.686178\n","resetting env. episode 868.000000, reward total was -21.000000. running mean: -19.699316\n","resetting env. episode 869.000000, reward total was -19.000000. running mean: -19.692323\n","resetting env. episode 870.000000, reward total was -20.000000. running mean: -19.695400\n","resetting env. episode 871.000000, reward total was -21.000000. running mean: -19.708446\n","resetting env. episode 872.000000, reward total was -20.000000. running mean: -19.711361\n","resetting env. episode 873.000000, reward total was -19.000000. running mean: -19.704248\n","resetting env. episode 874.000000, reward total was -19.000000. running mean: -19.697205\n","resetting env. episode 875.000000, reward total was -17.000000. running mean: -19.670233\n","resetting env. episode 876.000000, reward total was -18.000000. running mean: -19.653531\n","resetting env. episode 877.000000, reward total was -20.000000. running mean: -19.656995\n","resetting env. episode 878.000000, reward total was -21.000000. running mean: -19.670425\n","resetting env. episode 879.000000, reward total was -21.000000. running mean: -19.683721\n","resetting env. episode 880.000000, reward total was -20.000000. running mean: -19.686884\n","resetting env. episode 881.000000, reward total was -20.000000. running mean: -19.690015\n","resetting env. episode 882.000000, reward total was -19.000000. running mean: -19.683115\n","resetting env. episode 883.000000, reward total was -21.000000. running mean: -19.696284\n","resetting env. episode 884.000000, reward total was -19.000000. running mean: -19.689321\n","resetting env. episode 885.000000, reward total was -17.000000. running mean: -19.662428\n","resetting env. episode 886.000000, reward total was -19.000000. running mean: -19.655804\n","resetting env. episode 887.000000, reward total was -20.000000. running mean: -19.659245\n","resetting env. episode 888.000000, reward total was -17.000000. running mean: -19.632653\n","resetting env. episode 889.000000, reward total was -17.000000. running mean: -19.606327\n","resetting env. episode 890.000000, reward total was -21.000000. running mean: -19.620263\n","resetting env. episode 891.000000, reward total was -18.000000. running mean: -19.604061\n","resetting env. episode 892.000000, reward total was -20.000000. running mean: -19.608020\n","resetting env. episode 893.000000, reward total was -21.000000. running mean: -19.621940\n","resetting env. episode 894.000000, reward total was -19.000000. running mean: -19.615720\n","resetting env. episode 895.000000, reward total was -18.000000. running mean: -19.599563\n","resetting env. episode 896.000000, reward total was -20.000000. running mean: -19.603568\n","resetting env. episode 897.000000, reward total was -17.000000. running mean: -19.577532\n","resetting env. episode 898.000000, reward total was -18.000000. running mean: -19.561757\n","resetting env. episode 899.000000, reward total was -20.000000. running mean: -19.566139\n","resetting env. episode 900.000000, reward total was -19.000000. running mean: -19.560478\n","resetting env. episode 901.000000, reward total was -21.000000. running mean: -19.574873\n","resetting env. episode 902.000000, reward total was -20.000000. running mean: -19.579124\n","resetting env. episode 903.000000, reward total was -21.000000. running mean: -19.593333\n","resetting env. episode 904.000000, reward total was -20.000000. running mean: -19.597400\n","resetting env. episode 905.000000, reward total was -16.000000. running mean: -19.561426\n","resetting env. episode 906.000000, reward total was -20.000000. running mean: -19.565811\n","resetting env. episode 907.000000, reward total was -18.000000. running mean: -19.550153\n","resetting env. episode 908.000000, reward total was -20.000000. running mean: -19.554652\n","resetting env. episode 909.000000, reward total was -21.000000. running mean: -19.569105\n","resetting env. episode 910.000000, reward total was -19.000000. running mean: -19.563414\n","resetting env. episode 911.000000, reward total was -17.000000. running mean: -19.537780\n","resetting env. episode 912.000000, reward total was -19.000000. running mean: -19.532402\n","resetting env. episode 913.000000, reward total was -19.000000. running mean: -19.527078\n","resetting env. episode 914.000000, reward total was -21.000000. running mean: -19.541807\n","resetting env. episode 915.000000, reward total was -19.000000. running mean: -19.536389\n","resetting env. episode 916.000000, reward total was -18.000000. running mean: -19.521025\n","resetting env. episode 917.000000, reward total was -21.000000. running mean: -19.535815\n","resetting env. episode 918.000000, reward total was -19.000000. running mean: -19.530457\n","resetting env. episode 919.000000, reward total was -19.000000. running mean: -19.525152\n","resetting env. episode 920.000000, reward total was -19.000000. running mean: -19.519901\n","resetting env. episode 921.000000, reward total was -20.000000. running mean: -19.524702\n","resetting env. episode 922.000000, reward total was -19.000000. running mean: -19.519455\n","resetting env. episode 923.000000, reward total was -21.000000. running mean: -19.534260\n","resetting env. episode 924.000000, reward total was -18.000000. running mean: -19.518918\n","resetting env. episode 925.000000, reward total was -20.000000. running mean: -19.523729\n","resetting env. episode 926.000000, reward total was -19.000000. running mean: -19.518491\n","resetting env. episode 927.000000, reward total was -19.000000. running mean: -19.513306\n","resetting env. episode 928.000000, reward total was -16.000000. running mean: -19.478173\n","resetting env. episode 929.000000, reward total was -18.000000. running mean: -19.463392\n","resetting env. episode 930.000000, reward total was -21.000000. running mean: -19.478758\n","resetting env. episode 931.000000, reward total was -20.000000. running mean: -19.483970\n","resetting env. episode 932.000000, reward total was -19.000000. running mean: -19.479130\n","resetting env. episode 933.000000, reward total was -21.000000. running mean: -19.494339\n","resetting env. episode 934.000000, reward total was -19.000000. running mean: -19.489396\n","resetting env. episode 935.000000, reward total was -20.000000. running mean: -19.494502\n","resetting env. episode 936.000000, reward total was -19.000000. running mean: -19.489557\n","resetting env. episode 937.000000, reward total was -20.000000. running mean: -19.494661\n","resetting env. episode 938.000000, reward total was -21.000000. running mean: -19.509714\n","resetting env. episode 939.000000, reward total was -21.000000. running mean: -19.524617\n","resetting env. episode 940.000000, reward total was -21.000000. running mean: -19.539371\n","resetting env. episode 941.000000, reward total was -16.000000. running mean: -19.503977\n","resetting env. episode 942.000000, reward total was -21.000000. running mean: -19.518938\n","resetting env. episode 943.000000, reward total was -21.000000. running mean: -19.533748\n","resetting env. episode 944.000000, reward total was -17.000000. running mean: -19.508411\n","resetting env. episode 945.000000, reward total was -13.000000. running mean: -19.443327\n","resetting env. episode 946.000000, reward total was -21.000000. running mean: -19.458893\n","resetting env. episode 947.000000, reward total was -19.000000. running mean: -19.454305\n","resetting env. episode 948.000000, reward total was -16.000000. running mean: -19.419761\n","resetting env. episode 949.000000, reward total was -20.000000. running mean: -19.425564\n","resetting env. episode 950.000000, reward total was -19.000000. running mean: -19.421308\n","resetting env. episode 951.000000, reward total was -16.000000. running mean: -19.387095\n","resetting env. episode 952.000000, reward total was -21.000000. running mean: -19.403224\n","resetting env. episode 953.000000, reward total was -21.000000. running mean: -19.419192\n","resetting env. episode 954.000000, reward total was -18.000000. running mean: -19.405000\n","resetting env. episode 955.000000, reward total was -21.000000. running mean: -19.420950\n","resetting env. episode 956.000000, reward total was -19.000000. running mean: -19.416741\n","resetting env. episode 957.000000, reward total was -20.000000. running mean: -19.422573\n","resetting env. episode 958.000000, reward total was -16.000000. running mean: -19.388347\n","resetting env. episode 959.000000, reward total was -19.000000. running mean: -19.384464\n","resetting env. episode 960.000000, reward total was -19.000000. running mean: -19.380619\n","resetting env. episode 961.000000, reward total was -19.000000. running mean: -19.376813\n","resetting env. episode 962.000000, reward total was -19.000000. running mean: -19.373045\n","resetting env. episode 963.000000, reward total was -16.000000. running mean: -19.339314\n","resetting env. episode 964.000000, reward total was -16.000000. running mean: -19.305921\n","resetting env. episode 965.000000, reward total was -16.000000. running mean: -19.272862\n","resetting env. episode 966.000000, reward total was -20.000000. running mean: -19.280134\n","resetting env. episode 967.000000, reward total was -20.000000. running mean: -19.287332\n","resetting env. episode 968.000000, reward total was -20.000000. running mean: -19.294459\n","resetting env. episode 969.000000, reward total was -20.000000. running mean: -19.301514\n","resetting env. episode 970.000000, reward total was -20.000000. running mean: -19.308499\n","resetting env. episode 971.000000, reward total was -21.000000. running mean: -19.325414\n","resetting env. episode 972.000000, reward total was -17.000000. running mean: -19.302160\n","resetting env. episode 973.000000, reward total was -17.000000. running mean: -19.279138\n","resetting env. episode 974.000000, reward total was -20.000000. running mean: -19.286347\n","resetting env. episode 975.000000, reward total was -17.000000. running mean: -19.263484\n","resetting env. episode 976.000000, reward total was -19.000000. running mean: -19.260849\n","resetting env. episode 977.000000, reward total was -20.000000. running mean: -19.268240\n","resetting env. episode 978.000000, reward total was -20.000000. running mean: -19.275558\n","resetting env. episode 979.000000, reward total was -19.000000. running mean: -19.272802\n","resetting env. episode 980.000000, reward total was -19.000000. running mean: -19.270074\n","resetting env. episode 981.000000, reward total was -21.000000. running mean: -19.287373\n","resetting env. episode 982.000000, reward total was -18.000000. running mean: -19.274500\n","resetting env. episode 983.000000, reward total was -20.000000. running mean: -19.281755\n","resetting env. episode 984.000000, reward total was -21.000000. running mean: -19.298937\n","resetting env. episode 985.000000, reward total was -17.000000. running mean: -19.275948\n","resetting env. episode 986.000000, reward total was -19.000000. running mean: -19.273188\n","resetting env. episode 987.000000, reward total was -19.000000. running mean: -19.270456\n","resetting env. episode 988.000000, reward total was -19.000000. running mean: -19.267752\n","resetting env. episode 989.000000, reward total was -19.000000. running mean: -19.265074\n","resetting env. episode 990.000000, reward total was -21.000000. running mean: -19.282424\n","resetting env. episode 991.000000, reward total was -19.000000. running mean: -19.279599\n","resetting env. episode 992.000000, reward total was -18.000000. running mean: -19.266803\n","resetting env. episode 993.000000, reward total was -19.000000. running mean: -19.264135\n","resetting env. episode 994.000000, reward total was -21.000000. running mean: -19.281494\n","resetting env. episode 995.000000, reward total was -19.000000. running mean: -19.278679\n","resetting env. episode 996.000000, reward total was -19.000000. running mean: -19.275892\n","resetting env. episode 997.000000, reward total was -19.000000. running mean: -19.273133\n","resetting env. episode 998.000000, reward total was -20.000000. running mean: -19.280402\n","resetting env. episode 999.000000, reward total was -19.000000. running mean: -19.277598\n","resetting env. episode 1000.000000, reward total was -19.000000. running mean: -19.274822\n","resetting env. episode 1001.000000, reward total was -20.000000. running mean: -19.282074\n","resetting env. episode 1002.000000, reward total was -11.000000. running mean: -19.199253\n","resetting env. episode 1003.000000, reward total was -20.000000. running mean: -19.207261\n","resetting env. episode 1004.000000, reward total was -21.000000. running mean: -19.225188\n","resetting env. episode 1005.000000, reward total was -20.000000. running mean: -19.232936\n","resetting env. episode 1006.000000, reward total was -18.000000. running mean: -19.220607\n","resetting env. episode 1007.000000, reward total was -20.000000. running mean: -19.228401\n","resetting env. episode 1008.000000, reward total was -19.000000. running mean: -19.226117\n","resetting env. episode 1009.000000, reward total was -21.000000. running mean: -19.243855\n","resetting env. episode 1010.000000, reward total was -20.000000. running mean: -19.251417\n","resetting env. episode 1011.000000, reward total was -19.000000. running mean: -19.248903\n","resetting env. episode 1012.000000, reward total was -20.000000. running mean: -19.256414\n","resetting env. episode 1013.000000, reward total was -21.000000. running mean: -19.273850\n","resetting env. episode 1014.000000, reward total was -19.000000. running mean: -19.271111\n","resetting env. episode 1015.000000, reward total was -20.000000. running mean: -19.278400\n","resetting env. episode 1016.000000, reward total was -19.000000. running mean: -19.275616\n","resetting env. episode 1017.000000, reward total was -19.000000. running mean: -19.272860\n","resetting env. episode 1018.000000, reward total was -18.000000. running mean: -19.260131\n","resetting env. episode 1019.000000, reward total was -18.000000. running mean: -19.247530\n","resetting env. episode 1020.000000, reward total was -18.000000. running mean: -19.235055\n","resetting env. episode 1021.000000, reward total was -21.000000. running mean: -19.252704\n","resetting env. episode 1022.000000, reward total was -18.000000. running mean: -19.240177\n","resetting env. episode 1023.000000, reward total was -19.000000. running mean: -19.237775\n","resetting env. episode 1024.000000, reward total was -20.000000. running mean: -19.245397\n","resetting env. episode 1025.000000, reward total was -20.000000. running mean: -19.252944\n","resetting env. episode 1026.000000, reward total was -19.000000. running mean: -19.250414\n","resetting env. episode 1027.000000, reward total was -21.000000. running mean: -19.267910\n","resetting env. episode 1028.000000, reward total was -16.000000. running mean: -19.235231\n","resetting env. episode 1029.000000, reward total was -19.000000. running mean: -19.232879\n","resetting env. episode 1030.000000, reward total was -18.000000. running mean: -19.220550\n","resetting env. episode 1031.000000, reward total was -17.000000. running mean: -19.198344\n","resetting env. episode 1032.000000, reward total was -14.000000. running mean: -19.146361\n","resetting env. episode 1033.000000, reward total was -21.000000. running mean: -19.164897\n","resetting env. episode 1034.000000, reward total was -21.000000. running mean: -19.183248\n","resetting env. episode 1035.000000, reward total was -19.000000. running mean: -19.181416\n","resetting env. episode 1036.000000, reward total was -15.000000. running mean: -19.139602\n","resetting env. episode 1037.000000, reward total was -21.000000. running mean: -19.158206\n","resetting env. episode 1038.000000, reward total was -18.000000. running mean: -19.146624\n","resetting env. episode 1039.000000, reward total was -17.000000. running mean: -19.125157\n","resetting env. episode 1040.000000, reward total was -20.000000. running mean: -19.133906\n","resetting env. episode 1041.000000, reward total was -17.000000. running mean: -19.112567\n","resetting env. episode 1042.000000, reward total was -20.000000. running mean: -19.121441\n","resetting env. episode 1043.000000, reward total was -21.000000. running mean: -19.140227\n","resetting env. episode 1044.000000, reward total was -19.000000. running mean: -19.138824\n","resetting env. episode 1045.000000, reward total was -19.000000. running mean: -19.137436\n","resetting env. episode 1046.000000, reward total was -21.000000. running mean: -19.156062\n","resetting env. episode 1047.000000, reward total was -21.000000. running mean: -19.174501\n","resetting env. episode 1048.000000, reward total was -16.000000. running mean: -19.142756\n","resetting env. episode 1049.000000, reward total was -17.000000. running mean: -19.121329\n","resetting env. episode 1050.000000, reward total was -19.000000. running mean: -19.120115\n","resetting env. episode 1051.000000, reward total was -20.000000. running mean: -19.128914\n","resetting env. episode 1052.000000, reward total was -21.000000. running mean: -19.147625\n","resetting env. episode 1053.000000, reward total was -18.000000. running mean: -19.136149\n","resetting env. episode 1054.000000, reward total was -15.000000. running mean: -19.094787\n","resetting env. episode 1055.000000, reward total was -18.000000. running mean: -19.083839\n","resetting env. episode 1056.000000, reward total was -20.000000. running mean: -19.093001\n","resetting env. episode 1057.000000, reward total was -20.000000. running mean: -19.102071\n","resetting env. episode 1058.000000, reward total was -17.000000. running mean: -19.081050\n","resetting env. episode 1059.000000, reward total was -16.000000. running mean: -19.050240\n","resetting env. episode 1060.000000, reward total was -18.000000. running mean: -19.039737\n","resetting env. episode 1061.000000, reward total was -13.000000. running mean: -18.979340\n","resetting env. episode 1062.000000, reward total was -19.000000. running mean: -18.979547\n","resetting env. episode 1063.000000, reward total was -19.000000. running mean: -18.979751\n","resetting env. episode 1064.000000, reward total was -19.000000. running mean: -18.979954\n","resetting env. episode 1065.000000, reward total was -18.000000. running mean: -18.970154\n","resetting env. episode 1066.000000, reward total was -16.000000. running mean: -18.940452\n","resetting env. episode 1067.000000, reward total was -17.000000. running mean: -18.921048\n","resetting env. episode 1068.000000, reward total was -21.000000. running mean: -18.941837\n","resetting env. episode 1069.000000, reward total was -18.000000. running mean: -18.932419\n","resetting env. episode 1070.000000, reward total was -20.000000. running mean: -18.943095\n","resetting env. episode 1071.000000, reward total was -19.000000. running mean: -18.943664\n","resetting env. episode 1072.000000, reward total was -21.000000. running mean: -18.964227\n","resetting env. episode 1073.000000, reward total was -14.000000. running mean: -18.914585\n","resetting env. episode 1074.000000, reward total was -20.000000. running mean: -18.925439\n","resetting env. episode 1075.000000, reward total was -20.000000. running mean: -18.936185\n","resetting env. episode 1076.000000, reward total was -19.000000. running mean: -18.936823\n","resetting env. episode 1077.000000, reward total was -20.000000. running mean: -18.947455\n","resetting env. episode 1078.000000, reward total was -18.000000. running mean: -18.937980\n","resetting env. episode 1079.000000, reward total was -20.000000. running mean: -18.948600\n","resetting env. episode 1080.000000, reward total was -17.000000. running mean: -18.929114\n","resetting env. episode 1081.000000, reward total was -19.000000. running mean: -18.929823\n","resetting env. episode 1082.000000, reward total was -21.000000. running mean: -18.950525\n","resetting env. episode 1083.000000, reward total was -17.000000. running mean: -18.931020\n","resetting env. episode 1084.000000, reward total was -19.000000. running mean: -18.931710\n","resetting env. episode 1085.000000, reward total was -18.000000. running mean: -18.922392\n","resetting env. episode 1086.000000, reward total was -19.000000. running mean: -18.923169\n","resetting env. episode 1087.000000, reward total was -18.000000. running mean: -18.913937\n","resetting env. episode 1088.000000, reward total was -17.000000. running mean: -18.894797\n","resetting env. episode 1089.000000, reward total was -18.000000. running mean: -18.885850\n","resetting env. episode 1090.000000, reward total was -19.000000. running mean: -18.886991\n","resetting env. episode 1091.000000, reward total was -18.000000. running mean: -18.878121\n","resetting env. episode 1092.000000, reward total was -18.000000. running mean: -18.869340\n","resetting env. episode 1093.000000, reward total was -20.000000. running mean: -18.880646\n","resetting env. episode 1094.000000, reward total was -20.000000. running mean: -18.891840\n","resetting env. episode 1095.000000, reward total was -20.000000. running mean: -18.902922\n","resetting env. episode 1096.000000, reward total was -18.000000. running mean: -18.893892\n","resetting env. episode 1097.000000, reward total was -19.000000. running mean: -18.894953\n","resetting env. episode 1098.000000, reward total was -17.000000. running mean: -18.876004\n","resetting env. episode 1099.000000, reward total was -21.000000. running mean: -18.897244\n","resetting env. episode 1100.000000, reward total was -18.000000. running mean: -18.888271\n","resetting env. episode 1101.000000, reward total was -21.000000. running mean: -18.909389\n","resetting env. episode 1102.000000, reward total was -19.000000. running mean: -18.910295\n","resetting env. episode 1103.000000, reward total was -18.000000. running mean: -18.901192\n","resetting env. episode 1104.000000, reward total was -18.000000. running mean: -18.892180\n","resetting env. episode 1105.000000, reward total was -19.000000. running mean: -18.893258\n","resetting env. episode 1106.000000, reward total was -21.000000. running mean: -18.914326\n","resetting env. episode 1107.000000, reward total was -20.000000. running mean: -18.925182\n","resetting env. episode 1108.000000, reward total was -20.000000. running mean: -18.935931\n","resetting env. episode 1109.000000, reward total was -19.000000. running mean: -18.936571\n","resetting env. episode 1110.000000, reward total was -17.000000. running mean: -18.917206\n","resetting env. episode 1111.000000, reward total was -21.000000. running mean: -18.938033\n","resetting env. episode 1112.000000, reward total was -21.000000. running mean: -18.958653\n","resetting env. episode 1113.000000, reward total was -20.000000. running mean: -18.969067\n","resetting env. episode 1114.000000, reward total was -17.000000. running mean: -18.949376\n","resetting env. episode 1115.000000, reward total was -21.000000. running mean: -18.969882\n","resetting env. episode 1116.000000, reward total was -19.000000. running mean: -18.970183\n","resetting env. episode 1117.000000, reward total was -20.000000. running mean: -18.980482\n","resetting env. episode 1118.000000, reward total was -17.000000. running mean: -18.960677\n","resetting env. episode 1119.000000, reward total was -21.000000. running mean: -18.981070\n","resetting env. episode 1120.000000, reward total was -19.000000. running mean: -18.981259\n","resetting env. episode 1121.000000, reward total was -19.000000. running mean: -18.981447\n","resetting env. episode 1122.000000, reward total was -21.000000. running mean: -19.001632\n","resetting env. episode 1123.000000, reward total was -21.000000. running mean: -19.021616\n","resetting env. episode 1124.000000, reward total was -14.000000. running mean: -18.971400\n","resetting env. episode 1125.000000, reward total was -18.000000. running mean: -18.961686\n","resetting env. episode 1126.000000, reward total was -14.000000. running mean: -18.912069\n","resetting env. episode 1127.000000, reward total was -20.000000. running mean: -18.922948\n","resetting env. episode 1128.000000, reward total was -18.000000. running mean: -18.913719\n","resetting env. episode 1129.000000, reward total was -20.000000. running mean: -18.924581\n","resetting env. episode 1130.000000, reward total was -19.000000. running mean: -18.925336\n","resetting env. episode 1131.000000, reward total was -16.000000. running mean: -18.896082\n","resetting env. episode 1132.000000, reward total was -20.000000. running mean: -18.907121\n","resetting env. episode 1133.000000, reward total was -19.000000. running mean: -18.908050\n","resetting env. episode 1134.000000, reward total was -15.000000. running mean: -18.868970\n","resetting env. episode 1135.000000, reward total was -20.000000. running mean: -18.880280\n","resetting env. episode 1136.000000, reward total was -20.000000. running mean: -18.891477\n","resetting env. episode 1137.000000, reward total was -17.000000. running mean: -18.872563\n","resetting env. episode 1138.000000, reward total was -20.000000. running mean: -18.883837\n","resetting env. episode 1139.000000, reward total was -18.000000. running mean: -18.874999\n","resetting env. episode 1140.000000, reward total was -21.000000. running mean: -18.896249\n","resetting env. episode 1141.000000, reward total was -20.000000. running mean: -18.907286\n","resetting env. episode 1142.000000, reward total was -21.000000. running mean: -18.928213\n","resetting env. episode 1143.000000, reward total was -20.000000. running mean: -18.938931\n","resetting env. episode 1144.000000, reward total was -18.000000. running mean: -18.929542\n","resetting env. episode 1145.000000, reward total was -20.000000. running mean: -18.940246\n","resetting env. episode 1146.000000, reward total was -21.000000. running mean: -18.960844\n","resetting env. episode 1147.000000, reward total was -19.000000. running mean: -18.961235\n","resetting env. episode 1148.000000, reward total was -19.000000. running mean: -18.961623\n","resetting env. episode 1149.000000, reward total was -17.000000. running mean: -18.942007\n","resetting env. episode 1150.000000, reward total was -20.000000. running mean: -18.952587\n","resetting env. episode 1151.000000, reward total was -18.000000. running mean: -18.943061\n","resetting env. episode 1152.000000, reward total was -18.000000. running mean: -18.933630\n","resetting env. episode 1153.000000, reward total was -19.000000. running mean: -18.934294\n","resetting env. episode 1154.000000, reward total was -17.000000. running mean: -18.914951\n","resetting env. episode 1155.000000, reward total was -20.000000. running mean: -18.925802\n","resetting env. episode 1156.000000, reward total was -18.000000. running mean: -18.916544\n","resetting env. episode 1157.000000, reward total was -19.000000. running mean: -18.917378\n","resetting env. episode 1158.000000, reward total was -16.000000. running mean: -18.888204\n","resetting env. episode 1159.000000, reward total was -15.000000. running mean: -18.849322\n","resetting env. episode 1160.000000, reward total was -14.000000. running mean: -18.800829\n","resetting env. episode 1161.000000, reward total was -16.000000. running mean: -18.772821\n","resetting env. episode 1162.000000, reward total was -18.000000. running mean: -18.765093\n","resetting env. episode 1163.000000, reward total was -21.000000. running mean: -18.787442\n","resetting env. episode 1164.000000, reward total was -19.000000. running mean: -18.789567\n","resetting env. episode 1165.000000, reward total was -21.000000. running mean: -18.811672\n","resetting env. episode 1166.000000, reward total was -18.000000. running mean: -18.803555\n","resetting env. episode 1167.000000, reward total was -14.000000. running mean: -18.755519\n","resetting env. episode 1168.000000, reward total was -20.000000. running mean: -18.767964\n","resetting env. episode 1169.000000, reward total was -15.000000. running mean: -18.730284\n","resetting env. episode 1170.000000, reward total was -20.000000. running mean: -18.742982\n","resetting env. episode 1171.000000, reward total was -20.000000. running mean: -18.755552\n","resetting env. episode 1172.000000, reward total was -18.000000. running mean: -18.747996\n","resetting env. episode 1173.000000, reward total was -19.000000. running mean: -18.750516\n","resetting env. episode 1174.000000, reward total was -18.000000. running mean: -18.743011\n","resetting env. episode 1175.000000, reward total was -15.000000. running mean: -18.705581\n","resetting env. episode 1176.000000, reward total was -21.000000. running mean: -18.728525\n","resetting env. episode 1177.000000, reward total was -12.000000. running mean: -18.661240\n","resetting env. episode 1178.000000, reward total was -20.000000. running mean: -18.674628\n","resetting env. episode 1179.000000, reward total was -20.000000. running mean: -18.687881\n","resetting env. episode 1180.000000, reward total was -20.000000. running mean: -18.701002\n","resetting env. episode 1181.000000, reward total was -19.000000. running mean: -18.703992\n","resetting env. episode 1182.000000, reward total was -21.000000. running mean: -18.726953\n","resetting env. episode 1183.000000, reward total was -19.000000. running mean: -18.729683\n","resetting env. episode 1184.000000, reward total was -21.000000. running mean: -18.752386\n","resetting env. episode 1185.000000, reward total was -17.000000. running mean: -18.734862\n","resetting env. episode 1186.000000, reward total was -21.000000. running mean: -18.757514\n","resetting env. episode 1187.000000, reward total was -17.000000. running mean: -18.739939\n","resetting env. episode 1188.000000, reward total was -19.000000. running mean: -18.742539\n","resetting env. episode 1189.000000, reward total was -20.000000. running mean: -18.755114\n","resetting env. episode 1190.000000, reward total was -20.000000. running mean: -18.767563\n","resetting env. episode 1191.000000, reward total was -21.000000. running mean: -18.789887\n","resetting env. episode 1192.000000, reward total was -19.000000. running mean: -18.791988\n","resetting env. episode 1193.000000, reward total was -19.000000. running mean: -18.794068\n","resetting env. episode 1194.000000, reward total was -17.000000. running mean: -18.776128\n","resetting env. episode 1195.000000, reward total was -14.000000. running mean: -18.728366\n","resetting env. episode 1196.000000, reward total was -19.000000. running mean: -18.731083\n","resetting env. episode 1197.000000, reward total was -19.000000. running mean: -18.733772\n","resetting env. episode 1198.000000, reward total was -17.000000. running mean: -18.716434\n","resetting env. episode 1199.000000, reward total was -18.000000. running mean: -18.709270\n","resetting env. episode 1200.000000, reward total was -21.000000. running mean: -18.732177\n","resetting env. episode 1201.000000, reward total was -20.000000. running mean: -18.744855\n","resetting env. episode 1202.000000, reward total was -19.000000. running mean: -18.747407\n","resetting env. episode 1203.000000, reward total was -19.000000. running mean: -18.749933\n","resetting env. episode 1204.000000, reward total was -21.000000. running mean: -18.772433\n","resetting env. episode 1205.000000, reward total was -17.000000. running mean: -18.754709\n","resetting env. episode 1206.000000, reward total was -20.000000. running mean: -18.767162\n","resetting env. episode 1207.000000, reward total was -18.000000. running mean: -18.759490\n","resetting env. episode 1208.000000, reward total was -19.000000. running mean: -18.761895\n","resetting env. episode 1209.000000, reward total was -21.000000. running mean: -18.784276\n","resetting env. episode 1210.000000, reward total was -20.000000. running mean: -18.796434\n","resetting env. episode 1211.000000, reward total was -21.000000. running mean: -18.818469\n","resetting env. episode 1212.000000, reward total was -19.000000. running mean: -18.820285\n","resetting env. episode 1213.000000, reward total was -19.000000. running mean: -18.822082\n","resetting env. episode 1214.000000, reward total was -18.000000. running mean: -18.813861\n","resetting env. episode 1215.000000, reward total was -19.000000. running mean: -18.815722\n","resetting env. episode 1216.000000, reward total was -21.000000. running mean: -18.837565\n","resetting env. episode 1217.000000, reward total was -20.000000. running mean: -18.849189\n","resetting env. episode 1218.000000, reward total was -21.000000. running mean: -18.870698\n","resetting env. episode 1219.000000, reward total was -18.000000. running mean: -18.861991\n","resetting env. episode 1220.000000, reward total was -20.000000. running mean: -18.873371\n","resetting env. episode 1221.000000, reward total was -18.000000. running mean: -18.864637\n","resetting env. episode 1222.000000, reward total was -18.000000. running mean: -18.855991\n","resetting env. episode 1223.000000, reward total was -18.000000. running mean: -18.847431\n","resetting env. episode 1224.000000, reward total was -20.000000. running mean: -18.858956\n","resetting env. episode 1225.000000, reward total was -21.000000. running mean: -18.880367\n","resetting env. episode 1226.000000, reward total was -13.000000. running mean: -18.821563\n","resetting env. episode 1227.000000, reward total was -17.000000. running mean: -18.803348\n","resetting env. episode 1228.000000, reward total was -18.000000. running mean: -18.795314\n","resetting env. episode 1229.000000, reward total was -17.000000. running mean: -18.777361\n","resetting env. episode 1230.000000, reward total was -18.000000. running mean: -18.769587\n","resetting env. episode 1231.000000, reward total was -18.000000. running mean: -18.761891\n","resetting env. episode 1232.000000, reward total was -19.000000. running mean: -18.764273\n","resetting env. episode 1233.000000, reward total was -20.000000. running mean: -18.776630\n","resetting env. episode 1234.000000, reward total was -20.000000. running mean: -18.788864\n","resetting env. episode 1235.000000, reward total was -17.000000. running mean: -18.770975\n","resetting env. episode 1236.000000, reward total was -20.000000. running mean: -18.783265\n","resetting env. episode 1237.000000, reward total was -14.000000. running mean: -18.735432\n","resetting env. episode 1238.000000, reward total was -20.000000. running mean: -18.748078\n","resetting env. episode 1239.000000, reward total was -19.000000. running mean: -18.750597\n","resetting env. episode 1240.000000, reward total was -19.000000. running mean: -18.753091\n","resetting env. episode 1241.000000, reward total was -21.000000. running mean: -18.775560\n","resetting env. episode 1242.000000, reward total was -18.000000. running mean: -18.767805\n","resetting env. episode 1243.000000, reward total was -19.000000. running mean: -18.770127\n","resetting env. episode 1244.000000, reward total was -18.000000. running mean: -18.762426\n","resetting env. episode 1245.000000, reward total was -19.000000. running mean: -18.764801\n","resetting env. episode 1246.000000, reward total was -20.000000. running mean: -18.777153\n","resetting env. episode 1247.000000, reward total was -15.000000. running mean: -18.739382\n","resetting env. episode 1248.000000, reward total was -19.000000. running mean: -18.741988\n","resetting env. episode 1249.000000, reward total was -20.000000. running mean: -18.754568\n","resetting env. episode 1250.000000, reward total was -20.000000. running mean: -18.767022\n","resetting env. episode 1251.000000, reward total was -20.000000. running mean: -18.779352\n","resetting env. episode 1252.000000, reward total was -21.000000. running mean: -18.801559\n","resetting env. episode 1253.000000, reward total was -18.000000. running mean: -18.793543\n","resetting env. episode 1254.000000, reward total was -18.000000. running mean: -18.785608\n","resetting env. episode 1255.000000, reward total was -20.000000. running mean: -18.797752\n","resetting env. episode 1256.000000, reward total was -20.000000. running mean: -18.809774\n","resetting env. episode 1257.000000, reward total was -19.000000. running mean: -18.811676\n","resetting env. episode 1258.000000, reward total was -20.000000. running mean: -18.823560\n","resetting env. episode 1259.000000, reward total was -20.000000. running mean: -18.835324\n","resetting env. episode 1260.000000, reward total was -18.000000. running mean: -18.826971\n","resetting env. episode 1261.000000, reward total was -19.000000. running mean: -18.828701\n","resetting env. episode 1262.000000, reward total was -19.000000. running mean: -18.830414\n","resetting env. episode 1263.000000, reward total was -21.000000. running mean: -18.852110\n","resetting env. episode 1264.000000, reward total was -21.000000. running mean: -18.873589\n","resetting env. episode 1265.000000, reward total was -17.000000. running mean: -18.854853\n","resetting env. episode 1266.000000, reward total was -18.000000. running mean: -18.846304\n","resetting env. episode 1267.000000, reward total was -19.000000. running mean: -18.847841\n","resetting env. episode 1268.000000, reward total was -18.000000. running mean: -18.839363\n","resetting env. episode 1269.000000, reward total was -19.000000. running mean: -18.840969\n","resetting env. episode 1270.000000, reward total was -18.000000. running mean: -18.832560\n","resetting env. episode 1271.000000, reward total was -18.000000. running mean: -18.824234\n","resetting env. episode 1272.000000, reward total was -21.000000. running mean: -18.845992\n","resetting env. episode 1273.000000, reward total was -17.000000. running mean: -18.827532\n","resetting env. episode 1274.000000, reward total was -16.000000. running mean: -18.799256\n","resetting env. episode 1275.000000, reward total was -20.000000. running mean: -18.811264\n","resetting env. episode 1276.000000, reward total was -14.000000. running mean: -18.763151\n","resetting env. episode 1277.000000, reward total was -19.000000. running mean: -18.765520\n","resetting env. episode 1278.000000, reward total was -20.000000. running mean: -18.777864\n","resetting env. episode 1279.000000, reward total was -19.000000. running mean: -18.780086\n","resetting env. episode 1280.000000, reward total was -20.000000. running mean: -18.792285\n","resetting env. episode 1281.000000, reward total was -18.000000. running mean: -18.784362\n","resetting env. episode 1282.000000, reward total was -18.000000. running mean: -18.776518\n","resetting env. episode 1283.000000, reward total was -17.000000. running mean: -18.758753\n","resetting env. episode 1284.000000, reward total was -19.000000. running mean: -18.761166\n","resetting env. episode 1285.000000, reward total was -17.000000. running mean: -18.743554\n","resetting env. episode 1286.000000, reward total was -20.000000. running mean: -18.756119\n","resetting env. episode 1287.000000, reward total was -20.000000. running mean: -18.768557\n","resetting env. episode 1288.000000, reward total was -18.000000. running mean: -18.760872\n","resetting env. episode 1289.000000, reward total was -15.000000. running mean: -18.723263\n","resetting env. episode 1290.000000, reward total was -17.000000. running mean: -18.706030\n","resetting env. episode 1291.000000, reward total was -21.000000. running mean: -18.728970\n","resetting env. episode 1292.000000, reward total was -19.000000. running mean: -18.731680\n","resetting env. episode 1293.000000, reward total was -18.000000. running mean: -18.724364\n","resetting env. episode 1294.000000, reward total was -17.000000. running mean: -18.707120\n","resetting env. episode 1295.000000, reward total was -18.000000. running mean: -18.700049\n","resetting env. episode 1296.000000, reward total was -20.000000. running mean: -18.713048\n","resetting env. episode 1297.000000, reward total was -18.000000. running mean: -18.705918\n","resetting env. episode 1298.000000, reward total was -21.000000. running mean: -18.728859\n","resetting env. episode 1299.000000, reward total was -20.000000. running mean: -18.741570\n","resetting env. episode 1300.000000, reward total was -20.000000. running mean: -18.754154\n","resetting env. episode 1301.000000, reward total was -21.000000. running mean: -18.776613\n","resetting env. episode 1302.000000, reward total was -17.000000. running mean: -18.758847\n","resetting env. episode 1303.000000, reward total was -18.000000. running mean: -18.751258\n","resetting env. episode 1304.000000, reward total was -20.000000. running mean: -18.763746\n","resetting env. episode 1305.000000, reward total was -20.000000. running mean: -18.776108\n","resetting env. episode 1306.000000, reward total was -21.000000. running mean: -18.798347\n","resetting env. episode 1307.000000, reward total was -20.000000. running mean: -18.810364\n","resetting env. episode 1308.000000, reward total was -19.000000. running mean: -18.812260\n","resetting env. episode 1309.000000, reward total was -20.000000. running mean: -18.824137\n","resetting env. episode 1310.000000, reward total was -18.000000. running mean: -18.815896\n","resetting env. episode 1311.000000, reward total was -20.000000. running mean: -18.827737\n","resetting env. episode 1312.000000, reward total was -21.000000. running mean: -18.849460\n","resetting env. episode 1313.000000, reward total was -21.000000. running mean: -18.870965\n","resetting env. episode 1314.000000, reward total was -21.000000. running mean: -18.892255\n","resetting env. episode 1315.000000, reward total was -16.000000. running mean: -18.863333\n","resetting env. episode 1316.000000, reward total was -18.000000. running mean: -18.854700\n","resetting env. episode 1317.000000, reward total was -21.000000. running mean: -18.876153\n","resetting env. episode 1318.000000, reward total was -21.000000. running mean: -18.897391\n","resetting env. episode 1319.000000, reward total was -19.000000. running mean: -18.898417\n","resetting env. episode 1320.000000, reward total was -18.000000. running mean: -18.889433\n","resetting env. episode 1321.000000, reward total was -18.000000. running mean: -18.880539\n","resetting env. episode 1322.000000, reward total was -19.000000. running mean: -18.881733\n","resetting env. episode 1323.000000, reward total was -20.000000. running mean: -18.892916\n","resetting env. episode 1324.000000, reward total was -20.000000. running mean: -18.903987\n","resetting env. episode 1325.000000, reward total was -19.000000. running mean: -18.904947\n","resetting env. episode 1326.000000, reward total was -21.000000. running mean: -18.925897\n","resetting env. episode 1327.000000, reward total was -20.000000. running mean: -18.936638\n","resetting env. episode 1328.000000, reward total was -21.000000. running mean: -18.957272\n","resetting env. episode 1329.000000, reward total was -20.000000. running mean: -18.967699\n","resetting env. episode 1330.000000, reward total was -21.000000. running mean: -18.988022\n","resetting env. episode 1331.000000, reward total was -18.000000. running mean: -18.978142\n","resetting env. episode 1332.000000, reward total was -20.000000. running mean: -18.988361\n","resetting env. episode 1333.000000, reward total was -20.000000. running mean: -18.998477\n","resetting env. episode 1334.000000, reward total was -20.000000. running mean: -19.008492\n","resetting env. episode 1335.000000, reward total was -19.000000. running mean: -19.008407\n","resetting env. episode 1336.000000, reward total was -20.000000. running mean: -19.018323\n","resetting env. episode 1337.000000, reward total was -20.000000. running mean: -19.028140\n","resetting env. episode 1338.000000, reward total was -21.000000. running mean: -19.047859\n","resetting env. episode 1339.000000, reward total was -21.000000. running mean: -19.067380\n","resetting env. episode 1340.000000, reward total was -20.000000. running mean: -19.076706\n","resetting env. episode 1341.000000, reward total was -19.000000. running mean: -19.075939\n","resetting env. episode 1342.000000, reward total was -16.000000. running mean: -19.045180\n","resetting env. episode 1343.000000, reward total was -21.000000. running mean: -19.064728\n","resetting env. episode 1344.000000, reward total was -20.000000. running mean: -19.074081\n","resetting env. episode 1345.000000, reward total was -20.000000. running mean: -19.083340\n","resetting env. episode 1346.000000, reward total was -19.000000. running mean: -19.082507\n","resetting env. episode 1347.000000, reward total was -17.000000. running mean: -19.061682\n","resetting env. episode 1348.000000, reward total was -18.000000. running mean: -19.051065\n","resetting env. episode 1349.000000, reward total was -21.000000. running mean: -19.070554\n","resetting env. episode 1350.000000, reward total was -20.000000. running mean: -19.079849\n","resetting env. episode 1351.000000, reward total was -21.000000. running mean: -19.099050\n","resetting env. episode 1352.000000, reward total was -21.000000. running mean: -19.118060\n","resetting env. episode 1353.000000, reward total was -21.000000. running mean: -19.136879\n","resetting env. episode 1354.000000, reward total was -19.000000. running mean: -19.135510\n","resetting env. episode 1355.000000, reward total was -17.000000. running mean: -19.114155\n","resetting env. episode 1356.000000, reward total was -20.000000. running mean: -19.123013\n","resetting env. episode 1357.000000, reward total was -20.000000. running mean: -19.131783\n","resetting env. episode 1358.000000, reward total was -21.000000. running mean: -19.150466\n","resetting env. episode 1359.000000, reward total was -20.000000. running mean: -19.158961\n","resetting env. episode 1360.000000, reward total was -21.000000. running mean: -19.177371\n","resetting env. episode 1361.000000, reward total was -19.000000. running mean: -19.175598\n","resetting env. episode 1362.000000, reward total was -17.000000. running mean: -19.153842\n","resetting env. episode 1363.000000, reward total was -21.000000. running mean: -19.172303\n","resetting env. episode 1364.000000, reward total was -21.000000. running mean: -19.190580\n","resetting env. episode 1365.000000, reward total was -19.000000. running mean: -19.188674\n","resetting env. episode 1366.000000, reward total was -19.000000. running mean: -19.186788\n","resetting env. episode 1367.000000, reward total was -19.000000. running mean: -19.184920\n","resetting env. episode 1368.000000, reward total was -19.000000. running mean: -19.183070\n","resetting env. episode 1369.000000, reward total was -18.000000. running mean: -19.171240\n","resetting env. episode 1370.000000, reward total was -19.000000. running mean: -19.169527\n","resetting env. episode 1371.000000, reward total was -15.000000. running mean: -19.127832\n","resetting env. episode 1372.000000, reward total was -16.000000. running mean: -19.096554\n","resetting env. episode 1373.000000, reward total was -20.000000. running mean: -19.105588\n","resetting env. episode 1374.000000, reward total was -18.000000. running mean: -19.094532\n","resetting env. episode 1375.000000, reward total was -21.000000. running mean: -19.113587\n","resetting env. episode 1376.000000, reward total was -20.000000. running mean: -19.122451\n","resetting env. episode 1377.000000, reward total was -16.000000. running mean: -19.091227\n","resetting env. episode 1378.000000, reward total was -18.000000. running mean: -19.080314\n","resetting env. episode 1379.000000, reward total was -21.000000. running mean: -19.099511\n","resetting env. episode 1380.000000, reward total was -20.000000. running mean: -19.108516\n","resetting env. episode 1381.000000, reward total was -19.000000. running mean: -19.107431\n","resetting env. episode 1382.000000, reward total was -21.000000. running mean: -19.126357\n","resetting env. episode 1383.000000, reward total was -15.000000. running mean: -19.085093\n","resetting env. episode 1384.000000, reward total was -19.000000. running mean: -19.084242\n","resetting env. episode 1385.000000, reward total was -18.000000. running mean: -19.073400\n","resetting env. episode 1386.000000, reward total was -20.000000. running mean: -19.082666\n","resetting env. episode 1387.000000, reward total was -18.000000. running mean: -19.071839\n","resetting env. episode 1388.000000, reward total was -19.000000. running mean: -19.071121\n","resetting env. episode 1389.000000, reward total was -15.000000. running mean: -19.030410\n","resetting env. episode 1390.000000, reward total was -18.000000. running mean: -19.020105\n","resetting env. episode 1391.000000, reward total was -19.000000. running mean: -19.019904\n","resetting env. episode 1392.000000, reward total was -19.000000. running mean: -19.019705\n","resetting env. episode 1393.000000, reward total was -17.000000. running mean: -18.999508\n","resetting env. episode 1394.000000, reward total was -18.000000. running mean: -18.989513\n","resetting env. episode 1395.000000, reward total was -18.000000. running mean: -18.979618\n","resetting env. episode 1396.000000, reward total was -20.000000. running mean: -18.989822\n","resetting env. episode 1397.000000, reward total was -21.000000. running mean: -19.009924\n","resetting env. episode 1398.000000, reward total was -20.000000. running mean: -19.019824\n","resetting env. episode 1399.000000, reward total was -20.000000. running mean: -19.029626\n","resetting env. episode 1400.000000, reward total was -20.000000. running mean: -19.039330\n","resetting env. episode 1401.000000, reward total was -19.000000. running mean: -19.038937\n","resetting env. episode 1402.000000, reward total was -17.000000. running mean: -19.018547\n","resetting env. episode 1403.000000, reward total was -19.000000. running mean: -19.018362\n","resetting env. episode 1404.000000, reward total was -19.000000. running mean: -19.018178\n","resetting env. episode 1405.000000, reward total was -17.000000. running mean: -18.997996\n","resetting env. episode 1406.000000, reward total was -18.000000. running mean: -18.988016\n","resetting env. episode 1407.000000, reward total was -19.000000. running mean: -18.988136\n","resetting env. episode 1408.000000, reward total was -20.000000. running mean: -18.998255\n","resetting env. episode 1409.000000, reward total was -20.000000. running mean: -19.008272\n","resetting env. episode 1410.000000, reward total was -21.000000. running mean: -19.028190\n","resetting env. episode 1411.000000, reward total was -20.000000. running mean: -19.037908\n","resetting env. episode 1412.000000, reward total was -19.000000. running mean: -19.037529\n","resetting env. episode 1413.000000, reward total was -21.000000. running mean: -19.057153\n","resetting env. episode 1414.000000, reward total was -20.000000. running mean: -19.066582\n","resetting env. episode 1415.000000, reward total was -16.000000. running mean: -19.035916\n","resetting env. episode 1416.000000, reward total was -18.000000. running mean: -19.025557\n","resetting env. episode 1417.000000, reward total was -20.000000. running mean: -19.035301\n","resetting env. episode 1418.000000, reward total was -20.000000. running mean: -19.044948\n","resetting env. episode 1419.000000, reward total was -19.000000. running mean: -19.044499\n","resetting env. episode 1420.000000, reward total was -16.000000. running mean: -19.014054\n","resetting env. episode 1421.000000, reward total was -16.000000. running mean: -18.983913\n","resetting env. episode 1422.000000, reward total was -19.000000. running mean: -18.984074\n","resetting env. episode 1423.000000, reward total was -20.000000. running mean: -18.994233\n","resetting env. episode 1424.000000, reward total was -17.000000. running mean: -18.974291\n","resetting env. episode 1425.000000, reward total was -18.000000. running mean: -18.964548\n","resetting env. episode 1426.000000, reward total was -17.000000. running mean: -18.944903\n","resetting env. episode 1427.000000, reward total was -20.000000. running mean: -18.955454\n","resetting env. episode 1428.000000, reward total was -19.000000. running mean: -18.955899\n","resetting env. episode 1429.000000, reward total was -16.000000. running mean: -18.926340\n","resetting env. episode 1430.000000, reward total was -18.000000. running mean: -18.917077\n","resetting env. episode 1431.000000, reward total was -19.000000. running mean: -18.917906\n","resetting env. episode 1432.000000, reward total was -20.000000. running mean: -18.928727\n","resetting env. episode 1433.000000, reward total was -19.000000. running mean: -18.929440\n","resetting env. episode 1434.000000, reward total was -20.000000. running mean: -18.940145\n","resetting env. episode 1435.000000, reward total was -20.000000. running mean: -18.950744\n","resetting env. episode 1436.000000, reward total was -19.000000. running mean: -18.951236\n","resetting env. episode 1437.000000, reward total was -19.000000. running mean: -18.951724\n","resetting env. episode 1438.000000, reward total was -17.000000. running mean: -18.932207\n","resetting env. episode 1439.000000, reward total was -19.000000. running mean: -18.932885\n","resetting env. episode 1440.000000, reward total was -19.000000. running mean: -18.933556\n","resetting env. episode 1441.000000, reward total was -20.000000. running mean: -18.944220\n","resetting env. episode 1442.000000, reward total was -20.000000. running mean: -18.954778\n","resetting env. episode 1443.000000, reward total was -19.000000. running mean: -18.955230\n","resetting env. episode 1444.000000, reward total was -19.000000. running mean: -18.955678\n","resetting env. episode 1445.000000, reward total was -17.000000. running mean: -18.936121\n","resetting env. episode 1446.000000, reward total was -17.000000. running mean: -18.916760\n","resetting env. episode 1447.000000, reward total was -20.000000. running mean: -18.927592\n","resetting env. episode 1448.000000, reward total was -15.000000. running mean: -18.888316\n","resetting env. episode 1449.000000, reward total was -19.000000. running mean: -18.889433\n","resetting env. episode 1450.000000, reward total was -20.000000. running mean: -18.900539\n","resetting env. episode 1451.000000, reward total was -19.000000. running mean: -18.901534\n","resetting env. episode 1452.000000, reward total was -20.000000. running mean: -18.912518\n","resetting env. episode 1453.000000, reward total was -20.000000. running mean: -18.923393\n","resetting env. episode 1454.000000, reward total was -18.000000. running mean: -18.914159\n","resetting env. episode 1455.000000, reward total was -20.000000. running mean: -18.925018\n","resetting env. episode 1456.000000, reward total was -19.000000. running mean: -18.925767\n","resetting env. episode 1457.000000, reward total was -19.000000. running mean: -18.926510\n","resetting env. episode 1458.000000, reward total was -20.000000. running mean: -18.937245\n","resetting env. episode 1459.000000, reward total was -18.000000. running mean: -18.927872\n","resetting env. episode 1460.000000, reward total was -18.000000. running mean: -18.918593\n","resetting env. episode 1461.000000, reward total was -20.000000. running mean: -18.929407\n","resetting env. episode 1462.000000, reward total was -17.000000. running mean: -18.910113\n","resetting env. episode 1463.000000, reward total was -20.000000. running mean: -18.921012\n","resetting env. episode 1464.000000, reward total was -19.000000. running mean: -18.921802\n","resetting env. episode 1465.000000, reward total was -20.000000. running mean: -18.932584\n","resetting env. episode 1466.000000, reward total was -19.000000. running mean: -18.933258\n","resetting env. episode 1467.000000, reward total was -17.000000. running mean: -18.913926\n","resetting env. episode 1468.000000, reward total was -17.000000. running mean: -18.894786\n","resetting env. episode 1469.000000, reward total was -20.000000. running mean: -18.905839\n","resetting env. episode 1470.000000, reward total was -19.000000. running mean: -18.906780\n","resetting env. episode 1471.000000, reward total was -20.000000. running mean: -18.917712\n","resetting env. episode 1472.000000, reward total was -21.000000. running mean: -18.938535\n","resetting env. episode 1473.000000, reward total was -21.000000. running mean: -18.959150\n","resetting env. episode 1474.000000, reward total was -20.000000. running mean: -18.969558\n","resetting env. episode 1475.000000, reward total was -19.000000. running mean: -18.969863\n","resetting env. episode 1476.000000, reward total was -20.000000. running mean: -18.980164\n","resetting env. episode 1477.000000, reward total was -18.000000. running mean: -18.970363\n","resetting env. episode 1478.000000, reward total was -20.000000. running mean: -18.980659\n","resetting env. episode 1479.000000, reward total was -19.000000. running mean: -18.980852\n","resetting env. episode 1480.000000, reward total was -19.000000. running mean: -18.981044\n","resetting env. episode 1481.000000, reward total was -18.000000. running mean: -18.971233\n","resetting env. episode 1482.000000, reward total was -20.000000. running mean: -18.981521\n","resetting env. episode 1483.000000, reward total was -16.000000. running mean: -18.951706\n","resetting env. episode 1484.000000, reward total was -18.000000. running mean: -18.942189\n","resetting env. episode 1485.000000, reward total was -14.000000. running mean: -18.892767\n","resetting env. episode 1486.000000, reward total was -19.000000. running mean: -18.893839\n","resetting env. episode 1487.000000, reward total was -20.000000. running mean: -18.904901\n","resetting env. episode 1488.000000, reward total was -19.000000. running mean: -18.905852\n","resetting env. episode 1489.000000, reward total was -19.000000. running mean: -18.906793\n","resetting env. episode 1490.000000, reward total was -21.000000. running mean: -18.927725\n","resetting env. episode 1491.000000, reward total was -19.000000. running mean: -18.928448\n","resetting env. episode 1492.000000, reward total was -19.000000. running mean: -18.929164\n","resetting env. episode 1493.000000, reward total was -21.000000. running mean: -18.949872\n","resetting env. episode 1494.000000, reward total was -21.000000. running mean: -18.970373\n","resetting env. episode 1495.000000, reward total was -19.000000. running mean: -18.970670\n","resetting env. episode 1496.000000, reward total was -21.000000. running mean: -18.990963\n","resetting env. episode 1497.000000, reward total was -20.000000. running mean: -19.001053\n","resetting env. episode 1498.000000, reward total was -18.000000. running mean: -18.991043\n","resetting env. episode 1499.000000, reward total was -18.000000. running mean: -18.981132\n","resetting env. episode 1500.000000, reward total was -21.000000. running mean: -19.001321\n","CPU times: user 1h 31min 37s, sys: 41min 47s, total: 2h 13min 25s\n","Wall time: 1h 8min 57s\n"]}],"source":["%time hist3 = train_model(env, model, total_episodes=1500)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w2NblmwDsL3y","outputId":"61a37063-84e5-44de-df1b-9e591ce202c3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"name":"stdout","output_type":"stream","text":["Episode finished without success, accumulated reward = -6.0\n"]}],"source":["play_game(env, model)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"H=200_le_2.ipynb","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":0}